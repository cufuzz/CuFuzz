3.1. Using the Encoderï

The user should perform the below prerequisite steps before calling the nvJPEG encoding functions. See also nvJPEG Encoder Helper API Reference.


3.1.1. Encoding the Parametersï

The user should create an encoding parameters structure with nvjpegEncoderParamsCreate() function. The function will be initialized with default parameters. User can use an appropriate nvjpegEncoderParamsSet*() function to set a specific parameter.
The quality parameter can be set, using the nvjpegEncoderParamsSetQuality() function, to an integer value between 1 and 100, and this quality parameter will be used as a base for generating the JPEG quantization tables.
The parameters structure should be passed to compression functions.

Note
The encoding parameters structure can be reused to compress multiple images simultaneously, but no changes to the parameters should be made during the ongoing encoding, or the encoding result will be undefined.




3.1.2. Encoding the Stateï

The user should create the encoding state structure using nvjpegEncoderStateCreate() function. This function will hold intermediate buffers for the encoding process. This state should be passed to the compression functions.

Note
The encoding state structure can be reused to encode a series of images, but no encoding should be performed on multiple images with the same encoding state at the same timeâotherwise the result of the encodings will be undefined.




3.1.3. Encoding the Imageï

The nvJPEG library provides a few interfaces for compressing the image in different formats and colorspaces. See below.


3.1.3.1. nvjpegEncodeYUVï

Input for this function is an image in YUV colorspace. See nvjpegEncodeYUV(). The source argument should be filled with the corresponding YUV planar data. The chroma_subsampling argument should have the chroma subsampling of the input data. If the chroma subsampling in the encoding parameters is the same as input chroma subsampling, then the userâs input data will be directly used in the JPEG compression. Otherwise chroma will be resampled to match the chroma subsampling of the encoding parameters.
Input data should be provided with respect to the subsampling factors. That is, the chrominance image planes should have sizes aligned to the corresponding subsamplings. For example:

Image dimensions: 123x321
Input chroma subsampling: NVJPEG_CSS_410
Chroma subsampling factor for this chroma subsampling: 4x2

Given the above, the encoder library expects the user to provide:

Y plane with size: 123 x 321
Cb and Cr plane with size: 31 x 161






3.1.3.2. nvjpegEncodeImageï

See nvjpegEncodeImage(). Input for this function, i.e., how data should be provided in the source argument, is determined by the input_format argument. For the interleaved formats (ending with I) only the first channel is used. For the non-interleaved formats, all the channels in the input format are used.
For example, if the user has interleaved the RGB image of size W x H, stored continuously, and the pointer to it is pImage, then source should be:

source.channel[0] = pImage
source.pitch[0] = W*3

When the same image is stored in planar format, with image planes pointers stored continuously in the array pImage[3], then source should be:

source.channel[0] = pImage[0]
source.channel[1] = pImage[1]
source.channel[2] = pImage[2]

The pitch values for each channel in the source parameter should be set accordingly to the data layout.
The nvJPEG library will perform the color transformation to the YCbCr, and will compress the result.




3.1.4. Retrieving the Compressed Streamï

Often it is not feasible to accurately predict the final compressed data size of the final JPEG stream for any input data and parameters. The nvJPEG library, while encoding, will calculate the size of the final stream, allocate temporary buffer in the encoder state and save the compressed data in the encoding stateâs buffer. In order to get final compressed JPEG stream, the user should provide the memory buffer large enough to store this compressed data. There are two options for how to do this:


Use the upper bound on compressed JPEG stream size for the given parameters and image dimensions:

Use the nvjpegEncodeRetrieveBitstream() function to retrieve the maximum possible JPEG stream size at any given time.
Allocate the memory buffer at any given time.
Encode the image using one of the encoding functions.
Retrieve the compressed JPEG stream from the encoder state after successful encoding, using the nvjpegEncodeRetrieveBitstream() and the allocated buffer.



Wait for the encoding to complete, and retrieve the exact size of required buffer, as below:

Encode the image using one of the encoding functions.
Use the nvjpegEncodeRetrieveBitstream() function to retrieve the size in bytes of the compressed JPEG stream.
Allocate the memory buffer of at least this size.
Use the nvjpegEncodeRetrieveBitstream() function to populate your buffer with the compressed JPEG stream.




Note
As the same encoding image state can be reused to compress a series of images, the nvjpegEncodeRetrieveBitstream() function will return the result for the last compressed image.




3.1.5. JPEG Encoding Exampleï

See below the example code, and the block diagram shown in Figure 1 <nvjpeg-encode-examples__fig-nvjpeg-encode-example>, for encoding with nvJPEG Encoder.



JPEG Encoding Using nvJPEG Encoderï



nvjpegHandle_t nv_handle;
nvjpegEncoderState_t nv_enc_state;
nvjpegEncoderParams_t nv_enc_params;
cudaStream_t stream;

// initialize nvjpeg structures
nvjpegCreateSimple(&nv_handle);
nvjpegEncoderStateCreate(nv_handle, &nv_enc_state, stream);
nvjpegEncoderParamsCreate(nv_handle, &nv_enc_params, stream);

nvjpegImage_t nv_image;
// Fill nv_image with image data, let's say 640x480 image in RGB format

// Compress image
nvjpegEncodeImage(nv_handle, nv_enc_state, nv_enc_params,
    &nv_image, NVJPEG_INPUT_RGB, 640, 480, stream);

// get compressed stream size
size_t length;
nvjpegEncodeRetrieveBitstream(nv_handle, nv_enc_state, NULL, &length, stream);
// get stream itself
cudaStreamSynchronize(stream);
std::vector<char> jpeg(length);
nvjpegEncodeRetrieveBitstream(nv_handle, nv_enc_state, jpeg.data(), &length, 0);

// write stream to file
cudaStreamSynchronize(stream);
std::ofstream output_file("test.jpg", std::ios::out | std::ios::binary);
output_file.write(jpeg.data(), length);
output_file.close();