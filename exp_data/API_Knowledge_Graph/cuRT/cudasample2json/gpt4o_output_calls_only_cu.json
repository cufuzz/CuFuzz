{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu", "model_response": [{"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "vectorAddGPU", "tail_type": "__global__"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "basicStreamOrderedAllocation", "head_type": "__host__", "description": "Demonstrates stream ordered allocation using cudaMallocAsync/cudaFreeAsync APIs with default settings.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaDeviceGetDefaultMemPool", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaMemPoolSetAttribute", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "vectorAddGPU", "tail_type": "__global__"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "streamOrderedAllocationPostSync", "head_type": "__host__", "description": "Demonstrates stream ordered allocation with cudaMemPoolSetAttribute to control memory release.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu", "model_response": [{"head": "markSegments", "head_type": "__global__", "description": "Marks the first edge for each vertex in the edges flags.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "markSegments", "head_type": "__global__", "description": "Marks the first edge for each vertex in the edges flags.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "getSuccessors", "head_type": "__global__", "description": "Calculates successors for each vertex using data from edges.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "removeCycles", "head_type": "__global__", "description": "Removes cyclic successor dependencies.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "addScalar", "head_type": "__global__", "description": "Adds a scalar value to an array of startpoints.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "getRepresentatives", "head_type": "__global__", "description": "Gets representatives for vertices and shrinks chains.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "getVerticesMapping", "head_type": "__global__", "description": "Maps old vertex IDs to new vertex IDs.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "invalidateLoops", "head_type": "__global__", "description": "Invalidates self-loops in the reduced graph.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "calculateEdgesInfo", "head_type": "__global__", "description": "Calculates information about edges: startpoints, IDs, and weights.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "makeNewEdges", "head_type": "__global__", "description": "Builds new edges for the reduced graph and recalculates weights.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "Level::buildFromDeviceData", "head_type": "__host__", "description": "Copies device data to the host for a segmentation level.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "loadImage", "head_type": "__host__", "description": "Loads a PPM image file.", "relation": "calls", "tail": "__loadPPM", "tail_type": "CUDA_API"}, {"head": "loadImage", "head_type": "__host__", "description": "Loads a PPM image file.", "relation": "calls", "tail": "sdkFindFilePath", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::run", "head_type": "__device__", "description": "Executes the algorithm to build the segmentation tree.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::run", "head_type": "__device__", "description": "Executes the algorithm to build the segmentation tree.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::run", "head_type": "__device__", "description": "Executes the algorithm to build the segmentation tree.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::run", "head_type": "__device__", "description": "Executes the algorithm to build the segmentation tree.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::printMemoryUsage", "head_type": "__device__", "description": "Prints device memory usage information.", "relation": "calls", "tail": "cudaMemGetInfo", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::initalizeData", "head_type": "__device__", "description": "Initializes algorithm's internal data structures and preloads graph to device memory.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::invokeStep", "head_type": "__device__", "description": "Executes one step of the algorithm pipeline.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "SegmentationTreeBuilder::invokeStep", "head_type": "__device__", "description": "Executes one step of the algorithm pipeline.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/interval/interval.cu", "model_response": [{"head": "findCudaDevice", "head_type": "__host__", "description": "Finds and selects the best CUDA device available.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Retrieves device properties for the specified CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for GPU executions.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "__host__", "description": "Creates an event object for CUDA operations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFuncSetCacheConfig", "head_type": "__host__", "description": "Sets the preferred shared memory configuration for CUDA functions.", "relation": "calls", "tail": "test_interval_newton<T>", "tail_type": "CUDA_API"}, {"head": "cudaDeviceSetLimit", "head_type": "__host__", "description": "Sets a limit for GPU resources.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records a CUDA event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error for the CUDA runtime API.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Waits for all previous CUDA tasks to complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Computes the elapsed time between CUDA events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventDestroy", "head_type": "__host__", "description": "Destroys a CUDA event object.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the memory on the CUDA device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu", "model_response": [{"head": "copyP2PAndScale", "head_type": "__global__", "description": "This is a kernel function to scale elements from the source vector and store the result in the destination vector.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "getIdenticalGPUs", "head_type": "__host__", "description": "This function retrieves a list of identical GPUs that support memory pooling.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "getIdenticalGPUs", "head_type": "__host__", "description": "This function retrieves a list of identical GPUs that support memory pooling.", "relation": "calls", "tail": "cudaDeviceGetAttribute", "tail_type": "CUDA_API"}, {"head": "getP2PCapableGpuPair", "head_type": "__host__", "description": "This function selects two P2P-capable GPUs.", "relation": "calls", "tail": "getIdenticalGPUs", "tail_type": "CUDA_API"}, {"head": "getP2PCapableGpuPair", "head_type": "__host__", "description": "This function selects two P2P-capable GPUs.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "getP2PCapableGpuPair", "head_type": "__host__", "description": "This function selects two P2P-capable GPUs.", "relation": "calls", "tail": "cudaDeviceCanAccessPeer", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "getP2PCapableGpuPair", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaDeviceGetDefaultMemPool", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaMemPoolSetAccess", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "memPoolP2PCopy", "head_type": "__host__", "description": "This function demonstrates memory pooling and P2P memory copy operations.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu", "model_response": [{"head": "reduceBlock", "head_type": "__device__", "description": "A function that implements parallel reduction within a block.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "reduceBlock", "head_type": "__device__", "description": "A function that implements parallel reduction within a block.", "relation": "calls", "tail": "cg::reduce", "tail_type": "CUDA_API"}, {"head": "reduceBlock", "head_type": "__device__", "description": "A function that implements parallel reduction within a block.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "A CUDA kernel function that performs parallel sum reduction on an array using cooperative groups.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "A CUDA kernel function that performs parallel sum reduction on an array using cooperative groups.", "relation": "calls", "tail": "cg::this_grid", "tail_type": "CUDA_API"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "A CUDA kernel function that performs parallel sum reduction on an array using cooperative groups.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "A CUDA kernel function that performs parallel sum reduction on an array using cooperative groups.", "relation": "calls", "tail": "reduceBlock", "tail_type": "CUDA_API"}, {"head": "call_reduceSinglePassMultiBlockCG", "head_type": "__host__", "description": "A wrapper function for launching the kernel reduceSinglePassMultiBlockCG.", "relation": "calls", "tail": "cudaLaunchCooperativeKernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu", "model_response": [{"head": "verify_and_update_kernel", "head_type": "__global__", "description": "Verifies the values in readSurface whether they match the expected ones, and updates writeSurface with a new value.", "relation": "calls", "tail": "surf2Dread", "tail_type": "CUDA_API"}, {"head": "verify_and_update_kernel", "head_type": "__global__", "description": "Verifies the values in readSurface whether they match the expected ones, and updates writeSurface with a new value.", "relation": "calls", "tail": "make_uchar4", "tail_type": "CUDA_API"}, {"head": "verify_and_update_kernel", "head_type": "__global__", "description": "Verifies the values in readSurface whether they match the expected ones, and updates writeSurface with a new value.", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}, {"head": "getNumErrors", "head_type": "__global__", "description": "Retrieves the current number of errors encountered.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetValueMismatch", "head_type": "__device__", "description": "Checks if there is any value mismatch reported on the device side.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaGetValueMismatch", "head_type": "__device__", "description": "Checks if there is any value mismatch reported on the device side.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "cudaGetValueMismatch", "head_type": "__device__", "description": "Checks if there is any value mismatch reported on the device side.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "cudaGetValueMismatch", "head_type": "__device__", "description": "Checks if there is any value mismatch reported on the device side.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu", "model_response": [{"head": "cudaGetDevice", "head_type": "CUDA_API", "description": "Queries the current CUDA device.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "cudaGetDeviceProperties", "head_type": "CUDA_API", "description": "Obtains properties for the specified CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "CUDA_API", "description": "Creates a new event.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "CUDA_API", "description": "Records an event.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaEventSynchronize", "head_type": "CUDA_API", "description": "Waits for an event to complete.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaEventElapsedTime", "head_type": "CUDA_API", "description": "Computes the elapsed time between two events.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaEventDestroy", "head_type": "CUDA_API", "description": "Destroys an event.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu", "model_response": [{"head": "simpleKernel", "head_type": "__global__", "description": "simpleKernel function modifies a given device memory pointer with a specified value.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu", "model_response": [{"head": "shfl_scan_test", "head_type": "__global__", "description": "This function demonstrates basic use of the shuffle intrinsic to perform a scan operation across a block.", "relation": "calls", "tail": "__shfl_up_sync", "tail_type": "CUDA_API"}, {"head": "shfl_scan_test", "head_type": "__global__", "description": "This function demonstrates basic use of the shuffle intrinsic to perform a scan operation across a block.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "uniform_add", "head_type": "__global__", "description": "Uniform add: add partial sums array.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "CPUverify", "head_type": "__host__", "description": "This function verifies the shuffle scan result, for the simple prefix sum case.", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "CPUverify", "head_type": "__host__", "description": "This function verifies the shuffle scan result, for the simple prefix sum case.", "relation": "calls", "tail": "sdkResetTimer", "tail_type": "CUDA_API"}, {"head": "CPUverify", "head_type": "__host__", "description": "This function verifies the shuffle scan result, for the simple prefix sum case.", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "CPUverify", "head_type": "__host__", "description": "This function verifies the shuffle scan result, for the simple prefix sum case.", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "CPUverify", "head_type": "__host__", "description": "This function verifies the shuffle scan result, for the simple prefix sum case.", "relation": "calls", "tail": "sdkGetTimerValue", "tail_type": "CUDA_API"}, {"head": "shuffle_simple_test", "head_type": "__host__", "description": "This function tests shuffle scan using synthetic data, verifies computation speed and checks accuracy.", "relation": "calls", "tail": "shfl_scan_test", "tail_type": "CUDA_API"}, {"head": "shuffle_simple_test", "head_type": "__host__", "description": "This function tests shuffle scan using synthetic data, verifies computation speed and checks accuracy.", "relation": "calls", "tail": "uniform_add", "tail_type": "CUDA_API"}, {"head": "shuffle_integral_image_test", "head_type": "__host__", "description": "This function tests creation of an integral image using synthetic data, verifies computation and checks accuracy.", "relation": "calls", "tail": "shfl_intimage_rows", "tail_type": "CUDA_API"}, {"head": "shuffle_integral_image_test", "head_type": "__host__", "description": "This function tests creation of an integral image using synthetic data, verifies computation and checks accuracy.", "relation": "calls", "tail": "shfl_vertical_shfl", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu", "model_response": [{"head": "reduce", "head_type": "__device__", "description": "Performs a multipass reduction using parallel algorithms.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "reduce", "head_type": "__device__", "description": "Performs a multipass reduction using parallel algorithms.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "reduceSinglePass", "head_type": "__device__", "description": "Performs a single-pass reduction using parallel algorithms.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "reduceSinglePass", "head_type": "__device__", "description": "Performs a single-pass reduction using parallel algorithms.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "getNumBlocksAndThreads", "head_type": "__device__", "description": "Computes the number of threads and blocks to use for the reduction.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "benchmarkReduce", "head_type": "__device__", "description": "This function performs a reduction multiple times and measures the average reduction time.", "relation": "calls", "tail": "reduce", "tail_type": "CUDA_API"}, {"head": "benchmarkReduce", "head_type": "__device__", "description": "This function performs a reduction multiple times and measures the average reduction time.", "relation": "calls", "tail": "reduceSinglePass", "tail_type": "CUDA_API"}, {"head": "benchmarkReduce", "head_type": "__device__", "description": "This function performs a reduction multiple times and measures the average reduction time.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "benchmarkReduce", "head_type": "__device__", "description": "This function performs a reduction multiple times and measures the average reduction time.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu", "model_response": [{"head": "sequence_gpu", "head_type": "__global__", "description": "Fill a device array with the lane ID of each element using inline PTX.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/cudaGraphsPerfScaling/cudaGraphPerfScaling.cu", "model_response": [{"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Measures the time between two events on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "__globaltimer", "head_type": "__device__", "description": "Reads the current GPU global timer in a device kernel.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "delay", "head_type": "__global__", "description": "A kernel that induces a delay for a specified number of GPU clock cycles.", "relation": "calls", "tail": "clock64", "tail_type": "CUDA_API"}, {"head": "waitWithTimeout", "head_type": "__global__", "description": "A kernel that waits for a timeout or a latch trigger.", "relation": "calls", "tail": "__globaltimer", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates and captures a CUDA graph for parallel execution.", "relation": "calls", "tail": "cudaStreamBeginCapture", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates and captures a CUDA graph for parallel execution.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates and captures a CUDA graph for parallel execution.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates and captures a CUDA graph for parallel execution.", "relation": "calls", "tail": "cudaStreamEndCapture", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaGraphInstantiateWithFlags", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaGraphUpload", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs a captured CUDA graph to demonstrate various performance metrics.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/transpose/transpose.cu", "model_response": [{"head": "copy", "head_type": "__global__", "description": "The 'copy' kernel copies a tile of the matrix to output without transposing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "copySharedMem", "head_type": "__global__", "description": "The 'copySharedMem' kernel copies a tile of the matrix to output using shared memory.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "transposeNaive", "head_type": "__global__", "description": "The 'transposeNaive' kernel performs naive matrix transposition.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "transposeCoalesced", "head_type": "__global__", "description": "The 'transposeCoalesced' kernel performs coalesced matrix transposition.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "transposeNoBankConflicts", "head_type": "__global__", "description": "The 'transposeNoBankConflicts' kernel performs transposition with no bank conflicts.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "transposeDiagonal", "head_type": "__global__", "description": "The 'transposeDiagonal' kernel performs transposition along matrix diagonals.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "transposeFineGrained", "head_type": "__global__", "description": "The 'transposeFineGrained' kernel performs fine-grained partial transposition.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "transposeCoarseGrained", "head_type": "__global__", "description": "The 'transposeCoarseGrained' kernel performs coarse-grained partial transposition.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/alignedTypes/alignedTypes.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "A simple CUDA kernel that copies data from input to output on a per-element basis.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/LargeKernelParameter/LargeKernelParameter.cu", "model_response": [{"head": "kernelDefault", "head_type": "__global__", "description": "Kernel with 4KB kernel parameter limit.", "relation": "calls", "tail": "excess_params", "tail_type": "CUDA_CLASS"}, {"head": "kernelLargeParam", "head_type": "__global__", "description": "Kernel with 32,764 byte kernel parameter limit.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu", "model_response": [{"head": "compute_bf16gemm", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition using async copy.", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition using async copy.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition using async copy.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Compute the result of a matrix multiplication and addition using async copy.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_bf16gemm", "head_type": "__global__", "description": "Perform MxNxK matrix GEMM on bfloat16 matrices.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_bf16gemm", "head_type": "__global__", "description": "Perform MxNxK matrix GEMM on bfloat16 matrices.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_bf16gemm", "head_type": "__global__", "description": "Perform MxNxK matrix GEMM on bfloat16 matrices.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu", "model_response": [{"head": "Points::get_point", "head_type": "__host__ __device__", "description": "Get a point from the Points structure based on index.", "relation": "calls", "tail": "make_float2", "tail_type": "CUDA_API"}, {"head": "Points::set_point", "head_type": "__host__ __device__", "description": "Set a point in the Points structure based on index.", "relation": "none", "tail": "", "tail_type": ""}, {"head": "Bounding_box::compute_center", "head_type": "__host__ __device__", "description": "Compute the center of the Bounding_box.", "relation": "none", "tail": "", "tail_type": ""}, {"head": "Bounding_box::contains", "head_type": "__host__ __device__", "description": "Check if a Bounding_box contains a point.", "relation": "none", "tail": "", "tail_type": ""}, {"head": "Quadtree_node::bounding_box", "head_type": "__host__ __device__", "description": "Retrieve the bounding box of a Quadtree_node.", "relation": "none", "tail": "", "tail_type": ""}, {"head": "Random_generator::operator()", "head_type": "__host__ __device__", "description": "Generate a pair of random float values.", "relation": "calls", "tail": "thrust::make_tuple", "tail_type": "CUDA_CLASS"}, {"head": "cdpQuadtree", "head_type": "__host__", "description": "Allocate GPU structs, launch kernel and clean up for building a quadtree.", "relation": "calls", "tail": "build_quadtree_kernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu", "model_response": [{"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::this_grid", "tail_type": "CUDA_CLASS"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::tiled_partition", "tail_type": "CUDA_CLASS"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::binary_partition", "tail_type": "CUDA_CLASS"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::reduce", "tail_type": "CUDA_CLASS"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "CUDA kernel device code creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cooperative_groups::sync", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu", "model_response": [{"head": "bitonicsort_kernel", "head_type": "__device__", "description": "A kernel function that performs bitonic sorting on input data using shared memory.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "big_bitonicsort_kernel", "head_type": "__device__", "description": "A kernel function that performs bitonic sorting for larger inputs using shared memory.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "bitonicsort", "head_type": "__global__", "description": "An entry kernel function that performs bitonic sorting by calling bitonicsort_kernel.", "relation": "calls", "tail": "bitonicsort_kernel", "tail_type": "CUDA_API"}, {"head": "big_bitonicsort", "head_type": "__global__", "description": "An entry kernel function that performs bitonic sorting for large inputs by calling big_bitonicsort_kernel.", "relation": "calls", "tail": "big_bitonicsort_kernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu", "model_response": [{"head": "ringbufAlloc", "head_type": "__device__", "description": "The function dynamically allocates an element from a ring buffer to manage stack space for quicksort operations.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "ringbufFree", "head_type": "__device__", "description": "The function dynamically frees an element from the ring buffer and updates the tail index.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "ringbufFree", "head_type": "__device__", "description": "The function dynamically frees an element from the ring buffer and updates the tail index.", "relation": "calls", "tail": "atomicMax", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "cg::coalesced_threads", "tail_type": "CUDA_CLASS"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "ringbufAlloc", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "ringbufFree", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "__qsflo", "tail_type": "__device__"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "big_bitonicsort", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "bitonicsort", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "The function performs parallel warp-based quicksort utilizing ballot and atomic operations.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "qsort_warp", "tail_type": "__global__"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "bitonicsort", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "host", "description": "The host-side function organizes and launches the CUDA quicksort procedure using CDP.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "__qsflo", "head_type": "__device__", "description": "The function returns the index of the highest non-zero bit in a word using inline PTX.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu", "model_response": [{"head": "compute_gemm", "head_type": "__global__", "description": "Kernel computing matrix multiplication and addition using WMMA APIs and shared memory optimization.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm", "head_type": "__global__", "description": "Kernel computing matrix multiplication and addition using WMMA APIs and shared memory optimization.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm", "head_type": "__global__", "description": "Kernel computing matrix multiplication and addition using WMMA APIs and shared memory optimization.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Kernel performing less optimized GEMM using CUDA WMMA API.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Kernel performing less optimized GEMM using CUDA WMMA API.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Kernel performing less optimized GEMM using CUDA WMMA API.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "init_host_matrices", "head_type": "__host__", "description": "Function to initialize host matrices with random data.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "matMultiplyOnHost", "head_type": "__host__", "description": "Function to perform matrix multiplication on the host.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu", "model_response": [{"head": "print_info", "head_type": "__device__", "description": "Prints information about the current execution block or thread.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "cdp_kernel", "head_type": "__global__", "description": "A kernel function demonstrating CUDA dynamic parallelism with nested block launches.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "cdp_kernel", "head_type": "__global__", "description": "A kernel function demonstrating CUDA dynamic parallelism with nested block launches.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "cdp_kernel", "head_type": "__global__", "description": "A kernel function demonstrating CUDA dynamic parallelism with nested block launches.", "relation": "calls", "tail": "print_info", "tail_type": "CUDA_API"}, {"head": "cdp_kernel", "head_type": "__global__", "description": "A kernel function demonstrating CUDA dynamic parallelism with nested block launches.", "relation": "calls", "tail": "cdp_kernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu", "model_response": [{"head": "squareArray", "head_type": "__global__", "description": "Stores the square of each input element in output array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "negateArray", "head_type": "__global__", "description": "Stores the negative of each input element in output array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "createFreeGraph", "head_type": "__host__", "description": "Creates a CUDA graph to free memory using cudaGraphAddMemFreeNode.", "relation": "calls", "tail": "cudaGraphAddMemFreeNode", "tail_type": "CUDA_API"}, {"head": "createFreeGraph", "head_type": "__host__", "description": "Creates a CUDA graph to free memory using cudaGraphAddMemFreeNode.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "createFreeGraph", "head_type": "__host__", "description": "Creates a CUDA graph to free memory using cudaGraphAddMemFreeNode.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createFreeGraph", "head_type": "__host__", "description": "Creates a CUDA graph to free memory using cudaGraphAddMemFreeNode.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphAddMemAllocNode", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphAddMemcpyNode1D", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphAddKernelNode", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphAddMemFreeNode", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "__host__", "description": "Creates a CUDA graph explicitly with memory allocation and kernel nodes.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "__host__", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaStreamBeginCapture", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaStreamEndCapture", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphWithStreamCapture", "head_type": "__host__", "description": "Demonstrates creating a CUDA graph including memory nodes using stream capture.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "validateGPU", "head_type": "__global__", "description": "Validates the GPU results against reference results.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu", "model_response": [{"head": "printMemoryFootprint", "head_type": "__host__", "description": "Prints the memory footprint of a specific CUDA device.", "relation": "calls", "tail": "cudaDeviceGetGraphMemAttribute", "tail_type": "CUDA_API"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "prepareAllocParams", "tail_type": "CUDA_CLASS"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "cudaGraphAddMemAllocNode", "tail_type": "CUDA_API"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "cudaGraphAddMemFreeNode", "tail_type": "CUDA_API"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createVirtAddrReuseGraph", "head_type": "__host__", "description": "Creates a CUDA graph for virtual address reuse and instantiates it.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "createVirtAddrReuseGraph", "tail_type": "CUDA_CLASS"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "printMemoryFootprint", "tail_type": "CUDA_CLASS"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "virtualAddressReuseSingleGraph", "head_type": "__host__", "description": "Demonstrates virtual address reuse within a single CUDA graph.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "clockBlock", "head_type": "__global__", "description": "A CUDA kernel that performs no work but runs for a specified number of clocks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "prepareAllocParams", "tail_type": "CUDA_CLASS"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphAddMemAllocNode", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphAddKernelNode", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphAddMemFreeNode", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocFreeGraph", "head_type": "__host__", "description": "Creates a simple allocation and free graph with a kernel node and instantiates it.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "createSimpleAllocFreeGraph", "tail_type": "CUDA_CLASS"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "printMemoryFootprint", "tail_type": "CUDA_CLASS"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "physicalMemoryReuseSingleStream", "head_type": "__host__", "description": "Demonstrates physical memory reuse when running graphs sequentially on the same stream.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "createSimpleAllocFreeGraph", "tail_type": "CUDA_CLASS"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "printMemoryFootprint", "tail_type": "CUDA_CLASS"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "simultaneousStreams", "head_type": "__host__", "description": "Runs multiple graphs simultaneously on different streams, affecting the memory footprint.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocNoFreeGraph", "head_type": "__host__", "description": "Creates a simple CUDA graph with an allocation node and no freeing node.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocNoFreeGraph", "head_type": "__host__", "description": "Creates a simple CUDA graph with an allocation node and no freeing node.", "relation": "calls", "tail": "prepareAllocParams", "tail_type": "CUDA_CLASS"}, {"head": "createSimpleAllocNoFreeGraph", "head_type": "__host__", "description": "Creates a simple CUDA graph with an allocation node and no freeing node.", "relation": "calls", "tail": "cudaGraphAddMemAllocNode", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocNoFreeGraph", "head_type": "__host__", "description": "Creates a simple CUDA graph with an allocation node and no freeing node.", "relation": "calls", "tail": "cudaGraphInstantiate", "tail_type": "CUDA_API"}, {"head": "createSimpleAllocNoFreeGraph", "head_type": "__host__", "description": "Creates a simple CUDA graph with an allocation node and no freeing node.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "createSimpleAllocNoFreeGraph", "tail_type": "CUDA_CLASS"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "printMemoryFootprint", "tail_type": "CUDA_CLASS"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaDeviceGraphMemTrim", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaDeviceGraphMemTrim", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "unfreedAllocations", "head_type": "__host__", "description": "Runs multiple graphs on the same stream without freeing allocations.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "cleanupMemory", "head_type": "__host__", "description": "Trims device memory to clean up after examples.", "relation": "calls", "tail": "cudaDeviceGraphMemTrim", "tail_type": "CUDA_API"}, {"head": "cleanupMemory", "head_type": "__host__", "description": "Trims device memory to clean up after examples.", "relation": "calls", "tail": "printMemoryFootprint", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu", "model_response": [{"head": "memcpy_kernel", "head_type": "__global__", "description": "A global CUDA kernel that copies data from source array to destination array in memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "findCudaDevice", "head_type": "__host__", "description": "A host function to determine the CUDA device to run on.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "A host function to get the properties of a specified CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGetStreamPriorityRange", "head_type": "__host__", "description": "A host function that retrieves the range of priorities available for CUDA streams.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithPriority", "head_type": "__host__", "description": "A host function that creates a CUDA stream with a specified priority.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "A host function that allocates memory on the GPU device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "A host function that copies data between host and device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "__host__", "description": "A host function that creates a CUDA event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "A host function that records an event within a given stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "A host function that waits for an event to be completed.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "A host function that computes the elapsed time between two events.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu", "model_response": [{"head": "compute_tf32gemm", "head_type": "__global__", "description": "The compute_tf32gemm kernel computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm", "head_type": "__global__", "description": "The compute_tf32gemm kernel computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm", "head_type": "__global__", "description": "The compute_tf32gemm kernel computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "The compute_tf32gemm_async_copy kernel is a version of compute_tf32gemm using asynchronous copies.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "The compute_tf32gemm_async_copy kernel is a version of compute_tf32gemm using asynchronous copies.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "The compute_tf32gemm_async_copy kernel is a version of compute_tf32gemm using asynchronous copies.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "The simple_wmma_tf32gemm kernel performs a matrix multiplication with simplified assumptions and no reliance on shared memory.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "The simple_wmma_tf32gemm kernel performs a matrix multiplication with simplified assumptions and no reliance on shared memory.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "The simple_wmma_tf32gemm kernel performs a matrix multiplication with simplified assumptions and no reliance on shared memory.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphConditionalNodes/graphConditionalNodes.cu", "model_response": [{"head": "ifGraphKernelA", "head_type": "__global__", "description": "Kernel setting the conditional handle based on the value of a memory location.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "ifGraphKernelC", "head_type": "__global__", "description": "Kernel that prints a message from the GPU when executed.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "doWhileEmptyKernel", "head_type": "__global__", "description": "Placeholder kernel that prints a message for demonstration purposes.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "doWhileLoopKernel", "head_type": "__global__", "description": "Kernel that decrements a device memory location and terminates the loop when zero.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "capturedWhileKernel", "head_type": "__global__", "description": "Kernel evaluating a memory location and updating the conditional handle.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "capturedWhileEmptyKernel", "head_type": "__global__", "description": "Simple kernel that prints a message for a captured while loop.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu", "model_response": [{"head": "MatrixMulAsyncCopyMultiStageLargeChunk", "head_type": "__global__", "description": "Multi Stage memcpy_async pipeline with large chunk copy", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyMultiStageLargeChunk", "head_type": "__global__", "description": "Multi Stage memcpy_async pipeline with large chunk copy", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyLargeChunk", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with large copy chunk", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyLargeChunk", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with large copy chunk", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyLargeChunkAWBarrier", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk (float4) using arrive-wait barrier", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyLargeChunkAWBarrier", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk (float4) using arrive-wait barrier", "relation": "calls", "tail": "cuda::barrier", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopySingleStage", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with float copy", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopySingleStage", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with float copy", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyMultiStage", "head_type": "__global__", "description": "Multi Stage memcpy_async thread_scope_thread pipeline with single-element async-copy", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyMultiStage", "head_type": "__global__", "description": "Multi Stage memcpy_async thread_scope_thread pipeline with single-element async-copy", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyMultiStageSharedState", "head_type": "__global__", "description": "Multi Stage shared state memcpy_async pipeline thread_scope_block", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyMultiStageSharedState", "head_type": "__global__", "description": "Multi Stage shared state memcpy_async pipeline thread_scope_block", "relation": "calls", "tail": "cuda::pipeline_shared_state", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulNaive", "head_type": "__global__", "description": "Matrix multiplication (CUDA Kernel) on the device: C = A * B", "relation": "single", "tail": "", "tail_type": ""}, {"head": "MatrixMulNaiveLargeChunk", "head_type": "__global__", "description": "Matrix multiplication (CUDA Kernel) on the device with large chunk copy", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu", "model_response": [{"head": "compute_dgemm", "head_type": "__global__", "description": "Performs a double-precision matrix multiplication and addition using shared memory.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm", "head_type": "__global__", "description": "Performs a double-precision matrix multiplication and addition using shared memory.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm", "head_type": "__global__", "description": "Performs a double-precision matrix multiplication and addition using shared memory.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with async memory copies using pipelines.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with async memory copies using pipelines.", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with async memory copies using pipelines.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with async memory copies using pipelines.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with async memory copies using pipelines.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with cooperative group-based async memory copies.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with cooperative group-based async memory copies.", "relation": "calls", "tail": "cg::memcpy_async", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with cooperative group-based async memory copies.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with cooperative group-based async memory copies.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs matrix multiplication and addition with cooperative group-based async memory copies.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs double-precision matrix multiplication using WMMA API.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs double-precision matrix multiplication using WMMA API.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs double-precision matrix multiplication using WMMA API.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu", "model_response": [{"head": "reduce", "head_type": "__global__", "description": "The function performs reduction in a single CUDA kernel using shared memory and cooperative groups.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "reduce", "head_type": "__global__", "description": "The function performs reduction in a single CUDA kernel using shared memory and cooperative groups.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduce", "head_type": "__global__", "description": "The function performs reduction in a single CUDA kernel using shared memory and cooperative groups.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "reduceFinal", "head_type": "__global__", "description": "Final reduction kernel that sums the results from previous stages.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "reduceFinal", "head_type": "__global__", "description": "Final reduction kernel that sums the results from previous stages.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduceFinal", "head_type": "__global__", "description": "Final reduction kernel that sums the results from previous stages.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "myHostNodeCallback", "head_type": "__host__", "description": "Host callback function that processes results and performs necessary actions after CUDA operations.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu", "model_response": [{"head": "atomicAggInc", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic increment.", "relation": "calls", "tail": "cg::coalesced_threads", "tail_type": "CUDA_CLASS"}, {"head": "atomicAggInc", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic increment.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "atomicAggInc", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic increment.", "relation": "calls", "tail": "cg::coalesced_group::shfl", "tail_type": "CUDA_API"}, {"head": "filter_arr", "head_type": "__global__", "description": "A global kernel function to filter array with atomic increment.", "relation": "calls", "tail": "atomicAggInc", "tail_type": "CUDA_API"}, {"head": "atomicAggIncMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic multi bucket increment.", "relation": "calls", "tail": "cg::coalesced_threads", "tail_type": "CUDA_CLASS"}, {"head": "atomicAggIncMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic multi bucket increment.", "relation": "calls", "tail": "cg::labeled_partition", "tail_type": "CUDA_API"}, {"head": "atomicAggIncMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic multi bucket increment.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "atomicAggIncMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic multi bucket increment.", "relation": "calls", "tail": "cg::coalesced_group::shfl", "tail_type": "CUDA_API"}, {"head": "mapToBuckets", "head_type": "__global__", "description": "A global kernel function to map indices to buckets.", "relation": "calls", "tail": "atomicAggIncMulti", "tail_type": "CUDA_API"}, {"head": "atomicAggMaxMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic Max in multi bucket.", "relation": "calls", "tail": "cg::coalesced_threads", "tail_type": "CUDA_CLASS"}, {"head": "atomicAggMaxMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic Max in multi bucket.", "relation": "calls", "tail": "cg::labeled_partition", "tail_type": "CUDA_API"}, {"head": "atomicAggMaxMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic Max in multi bucket.", "relation": "calls", "tail": "cg::reduce", "tail_type": "CUDA_API"}, {"head": "atomicAggMaxMulti", "head_type": "__device__", "description": "A device function implementing warp-aggregated atomic Max in multi bucket.", "relation": "calls", "tail": "atomicMax", "tail_type": "CUDA_API"}, {"head": "calculateMaxInEachBuckets", "head_type": "__global__", "description": "A global kernel function to perform max calculation in each bucket.", "relation": "calls", "tail": "atomicAggMaxMulti", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu", "model_response": [{"head": "computeBezierLinePositions", "head_type": "__global__", "description": "Computes the positions of vertices for a Bezier line.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "computeBezierLinesCDP", "head_type": "__global__", "description": "Computes Bezier lines using CUDA Dynamic Parallelism.", "relation": "calls", "tail": "computeBezierLinePositions", "tail_type": "CUDA_API"}, {"head": "computeBezierLinesCDP", "head_type": "__global__", "description": "Computes Bezier lines using CUDA Dynamic Parallelism.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "computeBezierLinesCDP", "head_type": "__global__", "description": "Computes Bezier lines using CUDA Dynamic Parallelism.", "relation": "calls", "tail": "length", "tail_type": "__device__"}, {"head": "freeVertexMem", "head_type": "__global__", "description": "Frees vertex memory allocated for Bezier lines.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "length", "head_type": "__device__", "description": "Calculates the length of a float2 vector.", "relation": "calls", "tail": "sqrtf", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/newdelete/newdelete.cu", "model_response": [{"head": "vectorCreate", "head_type": "__global__", "description": "Kernel to allocate and instantiate Container objects on the device heap.", "relation": "calls", "tail": "Vector<int>", "tail_type": "CUDA_CLASS"}, {"head": "containerFill", "head_type": "__global__", "description": "Kernel to fill shared Container objects.", "relation": "calls", "tail": "push", "tail_type": "CUDA_API"}, {"head": "containerConsume", "head_type": "__global__", "description": "Kernel to consume data from shared Container objects.", "relation": "calls", "tail": "pop", "tail_type": "CUDA_API"}, {"head": "containerDelete", "head_type": "__global__", "description": "Kernel to delete shared Container objects.", "relation": "calls", "tail": "Container<int>", "tail_type": "CUDA_CLASS"}, {"head": "placementNew", "head_type": "__global__", "description": "Kernel for placement new of shared Vector objects and data in shared memory.", "relation": "calls", "tail": "Vector<int>", "tail_type": "CUDA_CLASS"}, {"head": "complexVector", "head_type": "__global__", "description": "Kernel using placement new for shared ComplexType Vector objects.", "relation": "calls", "tail": "Vector<ComplexType_t>", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu", "model_response": [{"head": "selection_sort", "head_type": "__device__", "description": "A selection sort uses when depth gets too big or the number of elements drops below a threshold.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cdp_simple_quicksort", "head_type": "__global__", "description": "A very basic quicksort algorithm, recursively launching the next level.", "relation": "calls", "tail": "selection_sort", "tail_type": "__device__"}, {"head": "cdp_simple_quicksort", "head_type": "__global__", "description": "A very basic quicksort algorithm, recursively launching the next level.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "cdp_simple_quicksort", "head_type": "__global__", "description": "A very basic quicksort algorithm, recursively launching the next level.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "run_qsort", "head_type": "__host__", "description": "A function to call the quicksort kernel from the host.", "relation": "calls", "tail": "cdp_simple_quicksort", "tail_type": "__global__"}, {"head": "run_qsort", "head_type": "__host__", "description": "A function to call the quicksort kernel from the host.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "initialize_data", "head_type": "__host__", "description": "A function to initialize data on the host using random values.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "check_results", "head_type": "__host__", "description": "A function to verify the results by copying data back to host.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "checkCmdLineFlag", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "getCmdLineArgumentInt", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "The main entry point where the execution begins.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu", "model_response": [{"head": "compute_gemm_imma", "head_type": "__global__", "description": "compute_gemm_imma kernel computes the result of a matrix multiplication and addition using high performance techniques.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "compute_gemm_imma kernel computes the result of a matrix multiplication and addition using high performance techniques.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "compute_gemm_imma kernel computes the result of a matrix multiplication and addition using high performance techniques.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "simple_wmma_gemm_imma kernel performs a less efficient GEMM computation without shared memory reliance.", "relation": "calls", "tail": "wmma::fill_fragment", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "simple_wmma_gemm_imma kernel performs a less efficient GEMM computation without shared memory reliance.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "simple_wmma_gemm_imma kernel performs a less efficient GEMM computation without shared memory reliance.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "simple_wmma_gemm_imma kernel performs a less efficient GEMM computation without shared memory reliance.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "init_host_matrices", "head_type": "__host__", "description": "init_host_matrices initializes matrices with random values on the host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "matMultiplyOnHost", "head_type": "__host__", "description": "matMultiplyOnHost multiplies matrices on host without GPU acceleration.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions based on a sine wave pattern.", "relation": "calls", "tail": "make_float4", "tail_type": "CUDA_API"}, {"head": "launch_kernel", "head_type": "__host__", "description": "Function to configure execution parameters and launch the simple_vbo_kernel.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "__global__"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object, runs CUDA kernel for vertex computation, and unmaps the buffer.", "relation": "calls", "tail": "cudaGraphicsMapResources", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object, runs CUDA kernel for vertex computation, and unmaps the buffer.", "relation": "calls", "tail": "cudaGraphicsResourceGetMappedPointer", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object, runs CUDA kernel for vertex computation, and unmaps the buffer.", "relation": "calls", "tail": "launch_kernel", "tail_type": "__host__"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object, runs CUDA kernel for vertex computation, and unmaps the buffer.", "relation": "calls", "tail": "cudaGraphicsUnmapResources", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs kernel for automatic testing, verifies results, and outputs data for comparison.", "relation": "calls", "tail": "launch_kernel", "tail_type": "__host__"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs kernel for automatic testing, verifies results, and outputs data for comparison.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs kernel for automatic testing, verifies results, and outputs data for comparison.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Initializes and runs either interactive or automated modes of CUDA operations.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Initializes and runs either interactive or automated modes of CUDA operations.", "relation": "calls", "tail": "runAutoTest", "tail_type": "__host__"}, {"head": "runTest", "head_type": "__host__", "description": "Initializes and runs either interactive or automated modes of CUDA operations.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Check GPU computation results or handle data for regression testing.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Check GPU computation results or handle data for regression testing.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions in sine wave pattern", "relation": "calls", "tail": "make_float4", "tail_type": "CUDA_API"}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launch the simple_vbo_kernel to execute the computation", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "__global__"}, {"head": "runCuda", "head_type": "__host__", "description": "Run the CUDA part of the computation using a mapped OpenGL buffer", "relation": "calls", "tail": "cudaGraphicsMapResources", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Run the CUDA part of the computation using a mapped OpenGL buffer", "relation": "calls", "tail": "cudaGraphicsResourceGetMappedPointer", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Run the CUDA part of the computation using a mapped OpenGL buffer", "relation": "calls", "tail": "launch_kernel", "tail_type": "__host__"}, {"head": "runCuda", "head_type": "__host__", "description": "Run the CUDA part of the computation using a mapped OpenGL buffer", "relation": "calls", "tail": "cudaGraphicsUnmapResources", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Run the CUDA part of an automated test and compare results", "relation": "calls", "tail": "launch_kernel", "tail_type": "__host__"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Run the CUDA part of an automated test and compare results", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Run the CUDA part of an automated test and compare results", "relation": "calls", "tail": "sdkDumpBin2", "tail_type": "CUDA_API"}, {"head": "createVBO", "head_type": "__host__", "description": "Create a Vertex Buffer Object and register it with CUDA", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}, {"head": "deleteVBO", "head_type": "__host__", "description": "Delete a Vertex Buffer Object and unregister it from CUDA", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/dxtc/dxtc.cu", "model_response": [{"head": "compress", "head_type": "__global__", "description": "Compress color block using DXT1 format.", "relation": "calls", "tail": "loadColorBlock", "tail_type": "CUDA_API"}, {"head": "compress", "head_type": "__global__", "description": "Compress color block using DXT1 format.", "relation": "calls", "tail": "evalAllPermutations", "tail_type": "CUDA_API"}, {"head": "compress", "head_type": "__global__", "description": "Compress color block using DXT1 format.", "relation": "calls", "tail": "findMinError", "tail_type": "CUDA_API"}, {"head": "compress", "head_type": "__global__", "description": "Compress color block using DXT1 format.", "relation": "calls", "tail": "saveBlockDXT1", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu", "model_response": [{"head": "cudaMalloc", "head_type": "CUDA_API", "description": "Allocates memory on the GPU device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "CUDA_API", "description": "Copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaCreateChannelDesc", "head_type": "CUDA_API", "description": "Creates a channel format descriptor.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaCreateTextureObject", "head_type": "CUDA_API", "description": "Creates a texture object.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "CUDA_API", "description": "Waits for the device to complete all preceding requested tasks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "CUDA_API", "description": "Creates an event object for synchronization or timing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "CUDA_API", "description": "Records an event at a specific point in a stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "CUDA_API", "description": "Waits until the completion of a specified event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "CUDA_API", "description": "Computes the elapsed time between two recorded events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "CUDA_API", "description": "Frees the memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu", "model_response": [{"head": "delay", "head_type": "__global__", "description": "The function 'delay' is a CUDA kernel for introducing a deliberate delay based on a timeout or a flag.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "copyp2p", "head_type": "__global__", "description": "The kernel 'copyp2p' performs peer-to-peer memory copy of integer data between GPUs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaOccupancyMaxPotentialBlockSize", "head_type": "CUDA_API", "description": "This API call computes the optimal launch configuration for a kernel to achieve maximum occupancy on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceCanAccessPeer", "head_type": "CUDA_API", "description": "This API call checks if a device can access the memory of a peer device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceEnablePeerAccess", "head_type": "CUDA_API", "description": "This API call enables peer access from the current device to a peer device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceDisablePeerAccess", "head_type": "CUDA_API", "description": "This API call disables peer access that had been enabled between two devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpyPeerAsync", "head_type": "CUDA_API", "description": "This API call performs an asynchronous memory copy between two devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "CUDA_API", "description": "This API records an event, which is used to measure the time taken by CUDA tasks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "CUDA_API", "description": "This API call computes the elapsed time between two events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithFlags", "head_type": "CUDA_API", "description": "This API creates a CUDA stream with specific flags, such as non-blocking.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamSynchronize", "head_type": "CUDA_API", "description": "This API call blocks the CPU until the specified CUDA stream has completed all operations.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu", "model_response": [{"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "initValue", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Performs the wavelet decomposition.", "relation": "calls", "tail": "dwtHaar1D", "tail_type": "CUDA_API"}, {"head": "getLevels", "head_type": "__host__", "description": "Determines the number of decomposition levels for a full decomposition.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu", "model_response": [{"head": "rgbaFloatToInt", "head_type": "__device__", "description": "convert floating point rgba color to 32-bit integer", "relation": "calls", "tail": "__saturatef", "tail_type": "CUDA_API"}, {"head": "rgbaIntToFloat", "head_type": "__device__", "description": "Convert 32-bit integer rgba color to floating point.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "d_boxfilter_rgba_x", "head_type": "__global__", "description": "row pass using texture lookups", "relation": "calls", "tail": "tex2DLod", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "column pass using coalesced global memory reads", "relation": "calls", "tail": "surf2Dread", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "column pass using coalesced global memory reads", "relation": "calls", "tail": "rgbaIntToFloat", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "column pass using coalesced global memory reads", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions in a sine wave pattern.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the kernel for execution.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object for writing from CUDA, executes the kernel, and unmaps the buffer object.", "relation": "calls", "tail": "cudaGraphicsMapResources", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object for writing from CUDA, executes the kernel, and unmaps the buffer object.", "relation": "calls", "tail": "cudaGraphicsResourceGetMappedPointer", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object for writing from CUDA, executes the kernel, and unmaps the buffer object.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps OpenGL buffer object for writing from CUDA, executes the kernel, and unmaps the buffer object.", "relation": "calls", "tail": "cudaGraphicsUnmapResources", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs the CUDA part of the computation for testing purposes.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs the CUDA part of the computation for testing purposes.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs the CUDA part of the computation for testing purposes.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs the CUDA part of the computation for testing purposes.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks if the CUDA computation result is correct.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks if the CUDA computation result is correct.", "relation": "calls", "tail": "checkCmdLineFlag", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks if the CUDA computation result is correct.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test to verify CUDA and OpenGL interoperability.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test to verify CUDA and OpenGL interoperability.", "relation": "calls", "tail": "runAutoTest", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test to verify CUDA and OpenGL interoperability.", "relation": "calls", "tail": "checkResultCuda", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test to verify CUDA and OpenGL interoperability.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test to verify CUDA and OpenGL interoperability.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions in sine wave pattern.", "relation": "calls", "tail": "make_float4", "tail_type": "CUDA_API"}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the simple_vbo_kernel CUDA kernel with specified parameters.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Runs the CUDA part of the computation by managing vertex buffer objects with CUDA kernels.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs an automated test of CUDA computations without OpenGL rendering, ensuring the correctness of the output.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks whether CUDA results are correct or exports them for external testing.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "readAndCompileShaderFromGLSLFile", "head_type": "__host__", "description": "Reads and compiles a GLSL shader program from a file.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ShaderCreate", "head_type": "__host__", "description": "Creates an OpenGL shader program using vertex and fragment shader files.", "relation": "calls", "tail": "readAndCompileShaderFromGLSLFile", "tail_type": "CUDA_API"}, {"head": "InitGraphicsState", "head_type": "__host__", "description": "Initializes the graphics state and OpenGL resources.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "display_thisframe", "head_type": "__host__", "description": "Handles the rendering for the current frame and updates CUDA computations.", "relation": "calls", "tail": "runCuda", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/matrixMul/matrixMul.cu", "model_response": [{"head": "MatrixMulCUDA", "head_type": "__global__", "description": "CUDA Kernel for performing matrix multiplication using shared memory and a tiling approach.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "CUDA_API", "description": "Allocates device memory for a given pointer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMallocHost", "head_type": "CUDA_API", "description": "Allocates pinned host memory for a given pointer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpyAsync", "head_type": "CUDA_API", "description": "Asynchronously copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithFlags", "head_type": "CUDA_API", "description": "Creates a CUDA stream with specific flags.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamSynchronize", "head_type": "CUDA_API", "description": "Synchronizes a given CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "CUDA_API", "description": "Creates a CUDA event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "CUDA_API", "description": "Records a CUDA event into a stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "CUDA_API", "description": "Synchronizes a CUDA event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "CUDA_API", "description": "Calculates the elapsed time in milliseconds between two events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "CUDA_API", "description": "Frees device memory previously allocated using cudaMalloc.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "CUDA_API", "description": "Frees pinned host memory previously allocated using cudaMallocHost.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaProfilerStart", "head_type": "CUDA_API", "description": "Starts the profiling of CUDA kernels.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaProfilerStop", "head_type": "CUDA_API", "description": "Stops the profiling of CUDA kernels.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform a layer of a layered 2D texture using texture lookups.", "relation": "calls", "tail": "tex2DLayered", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform a cubemap face of a linear buffer using cubemap texture lookups", "relation": "calls", "tail": "texCubemap", "tail_type": "CUDA_API"}, {"head": "cudaMalloc3DArray", "head_type": "__host__", "description": "Allocate memory for a 3D array", "relation": "calls", "tail": "cudaCreateChannelDesc", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy3D", "head_type": "__host__", "description": "Copies data between 3D objects", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object", "relation": "single", "tail": "", "tail_type": ""}, {"head": "getLastCudaError", "head_type": "__host__", "description": "Check for errors on the last CUDA call", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Wait for device to finish", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDestroyTextureObject", "head_type": "__host__", "description": "Destroys a texture object", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees device memory", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeArray", "head_type": "__host__", "description": "Frees memory allocated by cudaMalloc3DArray", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "A CUDA kernel that prints the block and thread id along with a given value.", "relation": "calls", "tail": "printf", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu", "model_response": [{"head": "reduceKernel", "head_type": "__global__", "description": "Simple reduction kernel using CUDA to perform data reduction on the GPU.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "SharedMemory", "tail_type": "CUDA_CLASS"}, {"head": "testKernel", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "testKernel", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "SharedMemory::getPointer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu", "model_response": [{"head": "shiftPitchLinear", "head_type": "__global__", "description": "Shifts matrix elements using pitch linear array", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "shiftArray", "head_type": "__global__", "description": "Shifts matrix elements using regular array", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu", "model_response": [{"head": "incKernel", "head_type": "__global__", "description": "A CUDA kernel that increments elements of input array and stores the result in output array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "processWithStreams", "head_type": "__host__", "description": "Function to process data with overlapping streams using CUDA streams and events.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Function to process data with overlapping streams using CUDA streams and events.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Function to process data with overlapping streams using CUDA streams and events.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Function to process data with overlapping streams using CUDA streams and events.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Function to process data with overlapping streams using CUDA streams and events.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "init", "head_type": "__host__", "description": "Initializes data for input processing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "test", "head_type": "__host__", "description": "Tests the results to ensure correctness after data processing.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu", "model_response": [{"head": "clock_block", "head_type": "__global__", "description": "This kernel performs a specified amount of clock cycles worth of computation.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sum", "head_type": "__global__", "description": "This kernel performs a reduction (sum) for a specified number of clock cycles.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "This kernel performs a reduction (sum) for a specified number of clock cycles.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu", "model_response": [{"head": "xyzw_frequency", "head_type": "__global__", "description": "Kernel function that uses count_if to find the frequency of specific characters 'x', 'y', 'z', or 'w' in a given text.", "relation": "calls", "tail": "count_if", "tail_type": "CUDA_API"}, {"head": "xyzw_frequency_thrust_device", "head_type": "__global__", "description": "Kernel function that utilizes Thrust library's count_if method with device execution policy to count specific characters.", "relation": "calls", "tail": "thrust::count_if", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu", "model_response": [{"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicAdd_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicExch_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicMax_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicMin_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicInc_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicDec_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicCAS_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicAnd_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicOr_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "A kernel for performing atomic operations on an array.", "relation": "calls", "tail": "atomicXor_system", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu", "model_response": [{"head": "cudaMallocManaged", "head_type": "__host__", "description": "A host function to allocate unified memory accessible by both CPU and GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "A host function to block the CPU until all previously submitted GPU tasks are complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "A host function to free the memory allocated using CUDA API.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamAttachMemAsync", "head_type": "__host__", "description": "A host API function to attach memory to a stream for either host or device access.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "A host function to block the current CPU thread until the specified stream has completed all tasks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cublasSetStream", "head_type": "__host__", "description": "A host function to set the stream where CUBLAS operations will be executed.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cublasDgemv", "head_type": "__host__", "description": "A host function to perform a matrix-vector multiplication on double precision floating-point numbers using cuBLAS.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreate", "head_type": "__host__", "description": "A host function to create a new CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cublasCreate", "head_type": "__host__", "description": "A host function to create a new cuBLAS handle.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamDestroy", "head_type": "__host__", "description": "A host function to destroy a CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cublasDestroy", "head_type": "__host__", "description": "A host function to destroy a cuBLAS handle.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "A host function to get properties of the CUDA device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu", "model_response": [{"head": "SimpleKernel", "head_type": "__global__", "description": "A simple CUDA kernel that scales input data by a factor of 2.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu", "model_response": [{"head": "kernelAddConstant", "head_type": "__global__", "description": "A kernel that increments each element of an array by a constant value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceCount", "head_type": "CUDA_API", "description": "Retrieves the number of CUDA-capable devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "CUDA_API", "description": "Retrieves the properties of the specified CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "CUDA_API", "description": "Sets the device to be used for subsequent CUDA API calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDevice", "head_type": "CUDA_API", "description": "Retrieves the current active CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "CUDA_API", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemset", "head_type": "CUDA_API", "description": "Initializes or sets device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "CUDA_API", "description": "Copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "CUDA_API", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "CUDA_API", "description": "Returns the last error that occurred during CUDA runtime API calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetErrorString", "head_type": "CUDA_API", "description": "Returns a string description of the error code.", "relation": "calls", "tail": "cudaGetLastError", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform an image using texture lookups.", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkFindFilePath", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkLoadPGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaCreateChannelDesc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMallocArray", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMemcpyToArray", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaCreateTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkSavePGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkWriteFile", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "compareData", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaDestroyTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaFreeArray", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu", "model_response": [{"head": "vectorAddGPU", "head_type": "__global__", "description": "A kernel function to add two vectors on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaSetDeviceFlags", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaHostRegister", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaHostAlloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaHostGetDevicePointer", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaHostUnregister", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility to check errors for a CUDA API function call.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "getLastCudaError", "head_type": "__host__", "description": "A utility function to check the last error after kernel execution.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu", "model_response": [{"head": "multiplyByTwo", "head_type": "__device__", "description": "The 'multiplyByTwo' function multiplies a given number by 2.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "divideByTwo", "head_type": "__device__", "description": "The 'divideByTwo' function divides a given number by 2.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu", "model_response": [{"head": "transformVector", "head_type": "__global__", "description": "Applies the __device__ function 'f' to each element of the vector 'v'.", "relation": "calls", "tail": "deviceFunc", "tail_type": "CUDA_CLASS"}, {"head": "transformVector", "head_type": "__global__", "description": "Applies the __device__ function 'f' to each element of the vector 'v'.", "relation": "calls", "tail": "*f", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu", "model_response": [{"head": "square", "head_type": "__global__", "description": "This kernel squares each element of the array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "Computes the potential occupancy of a given kernel and execution configuration.", "relation": "calls", "tail": "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "tail_type": "CUDA_API"}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "Computes the potential occupancy of a given kernel and execution configuration.", "relation": "calls", "tail": "cudaGetDevice", "tail_type": "CUDA_API"}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "Computes the potential occupancy of a given kernel and execution configuration.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "square", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "cudaOccupancyMaxPotentialBlockSize", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "Configures and launches the CUDA kernel with given execution configurations.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "Generates an array and launches square kernel to process the data, then verifies the result.", "relation": "calls", "tail": "launchConfig", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "Generates an array and launches square kernel to process the data, then verifies the result.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "Generates an array and launches square kernel to process the data, then verifies the result.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "Generates an array and launches square kernel to process the data, then verifies the result.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu", "model_response": [{"head": "VoteAnyKernel1", "head_type": "__global__", "description": "This kernel performs a vote any operation using CUDA intrinsics.", "relation": "calls", "tail": "dim3", "tail_type": "CUDA_API"}, {"head": "VoteAnyKernel1", "head_type": "__global__", "description": "This kernel performs a vote any operation using CUDA intrinsics.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "VoteAnyKernel1", "head_type": "__global__", "description": "This kernel performs a vote any operation using CUDA intrinsics.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "VoteAllKernel2", "head_type": "__global__", "description": "This kernel performs a vote all operation using CUDA intrinsics.", "relation": "calls", "tail": "dim3", "tail_type": "CUDA_API"}, {"head": "VoteAllKernel2", "head_type": "__global__", "description": "This kernel performs a vote all operation using CUDA intrinsics.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "VoteAllKernel2", "head_type": "__global__", "description": "This kernel performs a vote all operation using CUDA intrinsics.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "VoteAnyKernel3", "head_type": "__global__", "description": "This kernel performs a mixed vote any operation across multiple test cases.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu", "model_response": [{"head": "simpleKernel", "head_type": "__global__", "description": "A simple kernel that assigns a value 'val' to elements in an array.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu", "model_response": [{"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "thread_block", "tail_type": "CUDA_CLASS"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "sumReduction", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu", "model_response": [{"head": "reduceBlockData", "head_type": "__device__", "description": "This is a device function to reduce block data using Arrive-Wait Barrier.", "relation": "calls", "tail": "cuda::barrier", "tail_type": "CUDA_CLASS"}, {"head": "reduceBlockData", "head_type": "__device__", "description": "This is a device function to reduce block data using Arrive-Wait Barrier.", "relation": "calls", "tail": "cg::thread_block_tile", "tail_type": "CUDA_CLASS"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "This kernel normalizes vectors by dot product using Arrive-Wait Barrier.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "This kernel normalizes vectors by dot product using Arrive-Wait Barrier.", "relation": "calls", "tail": "cg::this_grid", "tail_type": "CUDA_API"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "This kernel normalizes vectors by dot product using Arrive-Wait Barrier.", "relation": "calls", "tail": "reduceBlockData", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "Tests assert function; threads whose id > N will print assertion failed error message.", "relation": "calls", "tail": "assert", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Executes the CUDA test and checks for device assertions.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Executes the CUDA test and checks for device assertions.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Executes the CUDA test and checks for device assertions.", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu", "model_response": [{"head": "vectorAdd", "head_type": "__global__", "description": "Computes the element-wise sum of vectors A and B into vector C.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the CUDA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetErrorString", "head_type": "__host__", "description": "Returns a string that represents the error code.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error during a runtime API operation.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the CUDA device.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the CUDA device.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the CUDA device.", "relation": "calls", "tail": "cudaGetErrorString", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/cppOverload/cppOverload.cu", "model_response": [{"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaFuncSetCacheConfig", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaFuncGetAttributes", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Ensures CUDA API calls are error-free, propagates errors if any arise.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "simple_kernel", "head_type": "__global__", "description": "A device code that demonstrates simple function overload using different input types.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu", "model_response": [{"head": "init_array", "head_type": "__global__", "description": "Initializes an array on the device with a specific value, using a given number of iterations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMallocHost", "head_type": "__host__", "description": "Allocates page-locked host memory that can be directly accessed by the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaHostRegister", "head_type": "__host__", "description": "Registers a piece of host memory, pinning it for direct access by the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaHostUnregister", "head_type": "__host__", "description": "Unregisters previously pinned host memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemset", "head_type": "__host__", "description": "Initializes or sets device memory to a fixed value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Performs a synchronous memory copy between host and device, or device to device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Performs an asynchronous memory copy between host and device, or device to device in a specified stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreate", "head_type": "__host__", "description": "Creates a new CUDA stream for asynchronous operations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamDestroy", "head_type": "__host__", "description": "Destroys a previously created CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreateWithFlags", "head_type": "__host__", "description": "Creates a CUDA event with specific flags.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in a specified stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "Synchronizes with a recorded event and blocks the host until it's triggered.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the time elapsed between two recorded events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventDestroy", "head_type": "__host__", "description": "Destroys a previously created CUDA event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for execution of CUDA calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Retrieves the number of CUDA-capable devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Gets properties of a specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDeviceFlags", "head_type": "__host__", "description": "Sets flags to be used during device initialization.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "__host__", "description": "Frees page-locked memory allocated with cudaMallocHost.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu", "model_response": [{"head": "increment_kernel", "head_type": "__global__", "description": "A CUDA kernel that increments elements at a given index in an array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "increment_kernel<<<blocks, threads, 0, 0>>>", "head_type": "__global__", "description": "A CUDA kernel launch with grid and block configuration.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "increment_kernel<<<blocks, threads, 0, 0>>>", "head_type": "__global__", "description": "A CUDA kernel launch with grid and block configuration.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "correct_output", "head_type": "__host__", "description": "Host function that checks the correctness of data in an array.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu", "model_response": [{"head": "surfaceWriteKernel", "head_type": "__global__", "description": "Write to a cuArray using surface writes", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}, {"head": "transformKernel", "head_type": "__global__", "description": "Transform an image using texture lookups", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu", "model_response": [{"head": "kernCacheSegmentTest", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "atomicExch", "tail_type": "CUDA_API"}, {"head": "kernCacheSegmentTest", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "kernCacheSegmentTest", "head_type": "__global__", "description": "Simple test kernel for device functionality", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "initAccessPolicyWindow", "head_type": "__host__", "description": "Initialize cuda access policy window", "relation": "single", "tail": "", "tail_type": ""}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaGetDeviceProperties)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaStreamCreate)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaDeviceSetLimit)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "initAccessPolicyWindow", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaMallocHost)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaMalloc)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaMemcpyAsync)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaStreamSetAttribute)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaCtxResetPersistingL2Cache)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaStreamSynchronize)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "kernCacheSegmentTest", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaFreeHost)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors(cudaFree)", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkGetTimerValue", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkDeleteTimer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/clock/clock.cu", "model_response": [{"head": "timedReduction", "head_type": "__global__", "description": "This kernel computes a parallel reduction and evaluates the time taken for each block.", "relation": "calls", "tail": "clock", "tail_type": "CUDA_API"}, {"head": "timedReduction", "head_type": "__global__", "description": "This kernel computes a parallel reduction and evaluates the time taken for each block.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu", "model_response": [{"head": "clock_block", "head_type": "__device__", "description": "This function runs for a specified number of clock ticks using modular arithmetic.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "kernel_A", "head_type": "__global__", "description": "This kernel calls clock_block() and is used to identify stream dependencies.", "relation": "calls", "tail": "clock_block", "tail_type": "CUDA_API"}, {"head": "kernel_B", "head_type": "__global__", "description": "Identical to kernel_A, this kernel calls clock_block() to identify dependencies.", "relation": "calls", "tail": "clock_block", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "Single-warp reduction kernel for summing clock values.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "sum", "head_type": "__global__", "description": "Single-warp reduction kernel for summing clock values.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu", "model_response": [{"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "Kernel for computing scalar product using CUDA intrinsics.", "relation": "calls", "tail": "__float2half2_rn", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "Kernel for computing scalar product using CUDA intrinsics.", "relation": "calls", "tail": "__hfma2", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "Kernel for computing scalar product using CUDA intrinsics.", "relation": "calls", "tail": "__low2float", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "Kernel for computing scalar product using CUDA intrinsics.", "relation": "calls", "tail": "__high2float", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "Kernel for computing scalar product using CUDA intrinsics.", "relation": "calls", "tail": "reduceInShared_intrinsics", "tail_type": "__device__"}, {"head": "scalarProductKernel_native", "head_type": "__global__", "description": "Kernel for computing scalar product using native CUDA operators.", "relation": "calls", "tail": "reduceInShared_native", "tail_type": "__device__"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Wrapper for checking CUDA errors.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Gets CUDA device properties.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMallocHost", "head_type": "__host__", "description": "Allocates page-locked memory on the host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "__host__", "description": "Frees page-locked memory on the host.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu", "model_response": [{"head": "runTest", "head_type": "__host__", "description": "Parse arguments, run appropriate CUDA tests.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Parse arguments, run appropriate CUDA tests.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Parse arguments, run appropriate CUDA tests.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Parse arguments, run appropriate CUDA tests.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "Run a bandwidth test based on parameters.", "relation": "calls", "tail": "testBandwidthQuick", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "Run a bandwidth test based on parameters.", "relation": "calls", "tail": "testBandwidthRange", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "Run a bandwidth test based on parameters.", "relation": "calls", "tail": "testBandwidthShmoo", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaHostAlloc", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to host transfer.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to device transfer.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to device transfer.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "Test the bandwidth of a device to device transfer.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu", "model_response": [{"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Retrieves the number of CUDA-capable devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGetP2PAttribute", "head_type": "__host__", "description": "Queries peer-to-peer attributes between devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Gets attributes about CUDA devices.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu", "model_response": [{"head": "cudlaModuleUnload", "head_type": "__host__", "description": "Unloads a CUDA module from memory through cuDLA API.", "relation": "calls", "tail": "cudlaModuleUnload", "tail_type": "CUDA_API"}, {"head": "cudlaDestroyDevice", "head_type": "__host__", "description": "Destroys a CUDA device through the cuDLA API.", "relation": "calls", "tail": "cudlaDestroyDevice", "tail_type": "CUDA_API"}, {"head": "cudlaSubmitTask", "head_type": "__host__", "description": "Submits a cuDLA task to the device.", "relation": "calls", "tail": "cudlaSubmitTask", "tail_type": "CUDA_API"}, {"head": "cudlaMemRegister", "head_type": "__host__", "description": "Registers CUDA memory with the cuDLA device.", "relation": "calls", "tail": "cudlaMemRegister", "tail_type": "CUDA_API"}, {"head": "cudlaCreateDevice", "head_type": "__host__", "description": "Creates a CUDA device for cuDLA operations.", "relation": "calls", "tail": "cudlaCreateDevice", "tail_type": "CUDA_API"}, {"head": "cudlaModuleLoadFromMemory", "head_type": "__host__", "description": "Loads a cuDLA module into GPU memory from a memory buffer.", "relation": "calls", "tail": "cudlaModuleLoadFromMemory", "tail_type": "CUDA_API"}, {"head": "cudlaModuleGetAttributes", "head_type": "__host__", "description": "Retrieves attributes of a cuDLA module.", "relation": "calls", "tail": "cudlaModuleGetAttributes", "tail_type": "CUDA_API"}, {"head": "cudlaMemUnregister", "head_type": "__host__", "description": "Unregisters previously registered memory with cuDLA.", "relation": "calls", "tail": "cudlaMemUnregister", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the CUDA device.", "relation": "calls", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the CUDA device to use.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a CUDA stream with specific flags.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the GPU.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Performs asynchronous memory copy operations.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaMemsetAsync", "head_type": "__host__", "description": "Sets memory on the device asynchronously.", "relation": "calls", "tail": "cudaMemsetAsync", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Waits for a stream to complete all operations.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "cudaStreamDestroy", "head_type": "__host__", "description": "Destroys a CUDA stream.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu", "model_response": [{"head": "initVectors", "head_type": "__global__", "description": "Initializes vectors rhs and x.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "r1_div_x", "head_type": "__global__", "description": "Calculates the ratio of r1 to r0 and assigns it to b.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "a_minus", "head_type": "__global__", "description": "Negates the value of a and assigns it to na.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu", "model_response": [{"head": "gpuSpMV", "head_type": "__device__", "description": "Performs sparse matrix-vector multiplication on the GPU.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuSaxpy", "head_type": "__device__", "description": "Performs the SAXPY operation on the GPU.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuDotProduct", "head_type": "__device__", "description": "Computes the dot product of two vectors on the GPU.", "relation": "calls", "tail": "cg::thread_block", "tail_type": "CUDA_CLASS"}, {"head": "gpuDotProduct", "head_type": "__device__", "description": "Computes the dot product of two vectors on the GPU.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuCopyVector", "head_type": "__device__", "description": "Copies one vector to another on the GPU.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuScaleVectorAndSaxpy", "head_type": "__device__", "description": "Combines vector scaling and SAXPY operation on the GPU.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Conjugate gradient solver for multiple GPUs.", "relation": "calls", "tail": "gpuSpMV", "tail_type": "CUDA_API"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Conjugate gradient solver for multiple GPUs.", "relation": "calls", "tail": "gpuSaxpy", "tail_type": "CUDA_API"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Conjugate gradient solver for multiple GPUs.", "relation": "calls", "tail": "gpuDotProduct", "tail_type": "CUDA_API"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Conjugate gradient solver for multiple GPUs.", "relation": "calls", "tail": "gpuCopyVector", "tail_type": "CUDA_API"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Conjugate gradient solver for multiple GPUs.", "relation": "calls", "tail": "gpuScaleVectorAndSaxpy", "tail_type": "CUDA_API"}, {"head": "PeerGroup::load_arrived", "head_type": "__device__", "description": "Loads the value of a synchronization arrival flag in a memory-safe manner.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "PeerGroup::store_arrived", "head_type": "__device__", "description": "Stores a synchronization arrival flag in a memory-safe manner.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "PeerGroup::sync", "head_type": "__device__", "description": "Synchronizes across multiple GPUs in a cooperative manner.", "relation": "calls", "tail": "load_arrived", "tail_type": "CUDA_API"}, {"head": "PeerGroup::sync", "head_type": "__device__", "description": "Synchronizes across multiple GPUs in a cooperative manner.", "relation": "calls", "tail": "store_arrived", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu", "model_response": [{"head": "gpuConjugateGradient", "head_type": "__global__", "description": "gpuConjugateGradient is a kernel function that performs the Conjugate Gradient method on a GPU.", "relation": "calls", "tail": "gpuSpMV", "tail_type": "__device__"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "gpuConjugateGradient is a kernel function that performs the Conjugate Gradient method on a GPU.", "relation": "calls", "tail": "gpuSaxpy", "tail_type": "__device__"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "gpuConjugateGradient is a kernel function that performs the Conjugate Gradient method on a GPU.", "relation": "calls", "tail": "gpuDotProduct", "tail_type": "__device__"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "gpuConjugateGradient is a kernel function that performs the Conjugate Gradient method on a GPU.", "relation": "calls", "tail": "gpuScaleVectorAndSaxpy", "tail_type": "__device__"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "gpuConjugateGradient is a kernel function that performs the Conjugate Gradient method on a GPU.", "relation": "calls", "tail": "gpuCopyVector", "tail_type": "__device__"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLALayerwiseStatsHybrid/main.cu", "model_response": [{"head": "cleanUp", "head_type": "__host__", "description": "The function cleanUp releases resources allocated in ResourceList.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "The function cleanUp releases resources allocated in ResourceList.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "The function cleanUp releases resources allocated in ResourceList.", "relation": "calls", "tail": "cudlaDestroyDevice", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "The function cleanUp releases resources allocated in ResourceList.", "relation": "calls", "tail": "cudlaModuleUnload", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu", "model_response": [{"head": "ComplexPointwiseMulAndScale", "head_type": "__device__", "description": "This function performs complex pointwise multiplication with scaling.", "relation": "calls", "tail": "ComplexMul", "tail_type": "__device__"}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__device__", "description": "This function performs complex pointwise multiplication with scaling.", "relation": "calls", "tail": "ComplexScale", "tail_type": "__device__"}, {"head": "ComplexAdd", "head_type": "__device__", "description": "This function adds two complex numbers.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexScale", "head_type": "__device__", "description": "This function scales a complex number by a scalar.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexMul", "head_type": "__device__", "description": "This function multiplies two complex numbers.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu", "model_response": [{"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Complex pointwise multiplication and scaling on the GPU.", "relation": "calls", "tail": "ComplexScale", "tail_type": "CUDA_API"}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Complex pointwise multiplication and scaling on the GPU.", "relation": "calls", "tail": "ComplexMul", "tail_type": "CUDA_API"}, {"head": "ComplexAdd", "head_type": "__device__ __host__", "description": "Complex addition operation for device and host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexScale", "head_type": "__device__ __host__", "description": "Complex scaling operation for device and host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexMul", "head_type": "__device__ __host__", "description": "Complex multiplication operation for device and host.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu", "model_response": [{"head": "solvePoisson", "head_type": "__global__", "description": "Kernel for solving Poisson equation on GPU.", "relation": "calls", "tail": "cufftComplex", "tail_type": "CUDA_CLASS"}, {"head": "solvePoissonEquation", "head_type": "__host__", "description": "Launch kernel on multiple GPUs.", "relation": "calls", "tail": "solvePoisson", "tail_type": "__global__"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Host function calls for CUDA error checking.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Host function calls for CUDA error checking.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for GPU executions.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftCreate", "head_type": "__host__", "description": "Creates a CUFFT plan.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtSetGPUs", "head_type": "__host__", "description": "Defines which GPUs to use for the CUFFT plan.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftMakePlan2d", "head_type": "__host__", "description": "Creates the plan for 2D FFT computations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtMalloc", "head_type": "__host__", "description": "Allocates FFT data on multiple GPUs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtMemcpy", "head_type": "__host__", "description": "Copies data with CUFFT descriptors between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtExecDescriptorC2C", "head_type": "__host__", "description": "Executes FFT on data across multiple GPUs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Wait for device to finish all operations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "getLastCudaError", "head_type": "__host__", "description": "Gets the last CUDA error that was generated.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtFree", "head_type": "__host__", "description": "Frees memory allocated with cufftXtMalloc for FFT data.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftDestroy", "head_type": "__host__", "description": "Destroys a CUFFT plan.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu", "model_response": [{"head": "cleanUp", "head_type": "__host__", "description": "Cleans up resources used in ResourceList.", "relation": "calls", "tail": "cudlaModuleUnload", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "Cleans up resources used in ResourceList.", "relation": "calls", "tail": "cudlaDestroyDevice", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "Cleans up resources used in ResourceList.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cleanUp", "head_type": "__host__", "description": "Cleans up resources used in ResourceList.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "printTensorDesc", "head_type": "__host__", "description": "Prints tensor descriptor details.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaCreateDevice", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaModuleLoadFromMemory", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaModuleGetAttributes", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaMemRegister", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaMemsetAsync", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaSubmitTask", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudlaGetLastError", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Main function orchestrating execution.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu", "model_response": [{"head": "computeAngles_kernel", "head_type": "__global__", "description": "Compute view angles for each point along the ray", "relation": "calls", "tail": "getLocation", "tail_type": "CUDA_API"}, {"head": "computeAngles_kernel", "head_type": "__global__", "description": "Compute view angles for each point along the ray", "relation": "calls", "tail": "tex2D<float>", "tail_type": "CUDA_API"}, {"head": "computeAngles_kernel", "head_type": "__global__", "description": "Compute view angles for each point along the ray", "relation": "calls", "tail": "getAngle", "tail_type": "CUDA_API"}, {"head": "computeVisibilities_kernel", "head_type": "__global__", "description": "Compute visibility for each point along the ray", "relation": "single", "tail": "", "tail_type": ""}, {"head": "lineOfSight_gold", "head_type": "__host__", "description": "Compute reference data set", "relation": "calls", "tail": "getLocation", "tail_type": "CUDA_API"}, {"head": "lineOfSight_gold", "head_type": "__host__", "description": "Compute reference data set", "relation": "calls", "tail": "getAngle", "tail_type": "CUDA_API"}, {"head": "getLocation", "head_type": "__device__ __host__", "description": "Compute the 2D coordinates of the point located at i steps from the origin of the ray", "relation": "single", "tail": "", "tail_type": ""}, {"head": "getAngle", "head_type": "__device__ __host__", "description": "Compute the angle of view between a 3D point and the origin of the ray", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu", "model_response": [{"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Performs complex pointwise multiplication and scales the result.", "relation": "calls", "tail": "ComplexMul", "tail_type": "__device__"}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Performs complex pointwise multiplication and scales the result.", "relation": "calls", "tail": "ComplexScale", "tail_type": "__device__"}]}
