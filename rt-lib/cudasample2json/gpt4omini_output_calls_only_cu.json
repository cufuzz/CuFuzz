{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu", "model_response": [{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "vectorAddGPU", "head_type": "__global__", "description": "Adds two vectors on the GPU.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaDeviceGetDefaultMemPool", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemPoolSetAttribute", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu", "model_response": [{"head": "cudaEventCreate", "head_type": "__host__", "description": "Creates an event that can be used for profiling.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in the specified stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "Waits until the event has completed.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the time between two events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemGetInfo", "head_type": "__host__", "description": "Retrieves information about the device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemset", "head_type": "__host__", "description": "Sets memory on the device to a specified value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "thrust::device_malloc", "head_type": "__device__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "thrust::device_free", "head_type": "__device__", "description": "Frees device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks and reports CUDA errors.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "markSegments", "head_type": "__global__", "description": "Kernel that marks segments for vertices.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "getSuccessors", "head_type": "__global__", "description": "Kernel that retrieves successors for vertices.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "removeCycles", "head_type": "__global__", "description": "Kernel that removes cycles in the graph.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "addScalar", "head_type": "__global__", "description": "Kernel that adds a scalar value to elements.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "getRepresentatives", "head_type": "__global__", "description": "Kernel that retrieves representative vertices.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "getVerticesMapping", "head_type": "__global__", "description": "Kernel that maps old vertices IDs to new.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "invalidateLoops", "head_type": "__global__", "description": "Kernel that invalidates self-loops in the graph.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "calculateEdgesInfo", "head_type": "__global__", "description": "Kernel that calculates information on edges.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "makeNewEdges", "head_type": "__global__", "description": "Kernel that reconstructs new edges.", "relation": "calls", "tail": "thrust::device_ptr", "tail_type": "CUDA_API"}, {"head": "__savePPM", "head_type": "__device__", "description": "Saves the image in PPM format.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "loadImage", "head_type": "__host__", "description": "Loads a PPM image from file.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "buildGraph", "head_type": "__host__", "description": "Builds the graph representation from the image.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "thrust::sort", "head_type": "__device__", "description": "Sorts elements on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "thrust::adjacent_difference", "head_type": "__device__", "description": "Computes the adjacent difference.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/interval/interval.cu", "model_response": [{"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to use for CUDA functions", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "__host__", "description": "Creates an event object", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFuncSetCacheConfig", "head_type": "__host__", "description": "Set the cache configuration for a specified function", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSetLimit", "head_type": "__host__", "description": "Set limits on device parameters", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error generated by the previous runtime API call", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "Blocks until the event is complete", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory between host and device", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the elapsed time between two events", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventDestroy", "head_type": "__host__", "description": "Destroys an event object", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees device memory", "relation": "single", "tail": "", "tail_type": ""}, {"head": "test_interval_newton", "head_type": "__global__", "description": "Tests the interval Newton method on the GPU", "relation": "calls", "tail": "cudaGetLastError", "tail_type": "CUDA_API"}, {"head": "test_interval_newton_cpu", "head_type": "__host__", "description": "Computes the results using a CPU implementation based on the Boost library", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu", "model_response": [{"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Gets the number of GPU devices available.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Retrieves various device attributes.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Retrieves various device attributes.", "relation": "calls", "tail": "cudaDevAttrMemoryPoolsSupported", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Retrieves various device attributes.", "relation": "calls", "tail": "cudaDevAttrComputeCapabilityMajor", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Retrieves various device attributes.", "relation": "calls", "tail": "cudaDevAttrComputeCapabilityMinor", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for subsequent CUDA calls.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for subsequent CUDA calls.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "cudaMallocAsync", "head_type": "__host__", "description": "Allocates memory asynchronously.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data asynchronously from host to device.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in a stream.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for subsequent CUDA calls.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "cudaMallocAsync", "head_type": "__host__", "description": "Allocates memory asynchronously.", "relation": "calls", "tail": "cudaMemPoolSetAccess", "tail_type": "CUDA_API"}, {"head": "cudaMemPoolSetAccess", "head_type": "__host__", "description": "Sets access permissions for a memory pool.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data asynchronously from device to host.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, {"head": "cudaFreeAsync", "head_type": "__host__", "description": "Frees allocated memory asynchronously.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "cudaEventCreate", "head_type": "__host__", "description": "Creates an event.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a stream with specified flags.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaStreamWaitEvent", "head_type": "__host__", "description": "Waits for an event to be recorded in a stream.", "relation": "calls", "tail": "copyP2PAndScale", "tail_type": "CUDA_API"}, {"head": "copyP2PAndScale", "head_type": "__global__", "description": "Copies and scales the elements from the source vector to the destination vector.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu", "model_response": [{"head": "reduceBlock", "head_type": "__device__", "description": "Reduces a block of values using shared memory.", "relation": "calls", "tail": "cg::reduce", "tail_type": "CUDA_API"}, {"head": "reduceBlock", "head_type": "__device__", "description": "Reduces a block of values using shared memory.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "Reduces an arbitrary size array in a single kernel invocation.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "Reduces an arbitrary size array in a single kernel invocation.", "relation": "calls", "tail": "cg::this_grid", "tail_type": "CUDA_CLASS"}, {"head": "reduceSinglePassMultiBlockCG", "head_type": "__global__", "description": "Reduces an arbitrary size array in a single kernel invocation.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "call_reduceSinglePassMultiBlockCG", "head_type": "function", "description": "Wrapper function for launching single-pass multi-block reduction kernel.", "relation": "calls", "tail": "cudaLaunchCooperativeKernel", "tail_type": "CUDA_API"}, {"head": "getNumBlocksAndThreads", "head_type": "function", "description": "Computes the number of blocks and threads for the reduction.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu", "model_response": [{"head": "cuInit", "head_type": "__host__", "description": "Initializes the CUDA driver API.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuCtxCreate", "head_type": "__host__", "description": "Creates a new context for the specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuCtxPushCurrent", "head_type": "__host__", "description": "Makes the specified context the current context.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuDeviceGetAttribute", "head_type": "__host__", "description": "Returns the value of a specified device attribute.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuGraphicsEGLRegisterImage", "head_type": "__host__", "description": "Registers an EGLImage for CUDA graphics access.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuGraphicsSubResourceGetMappedArray", "head_type": "__host__", "description": "Gets the array from the CUDA-registered graphics resource.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuStreamCreate", "head_type": "__host__", "description": "Creates a new CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuEventCreate", "head_type": "__host__", "description": "Creates an event object.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuStreamWaitEvent", "head_type": "__host__", "description": "Waits for an event to trigger.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuCtxSynchronize", "head_type": "__host__", "description": "Blocks until all previously submitted tasks in the stream are complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cuGraphicsUnregisterResource", "head_type": "__host__", "description": "Unregisters a CUDA graphics resource.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "verify_and_update_kernel", "head_type": "__global__", "description": "Kernel that verifies data read from a surface and updates it.", "relation": "calls", "tail": "getNumErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Waits for the device to complete all preceding tasks.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu", "model_response": [{"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "checkCmdLineFlag", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "getCmdLineArgumentInt", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaGetDevice", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::host_vector", "tail_type": "CUDA_CLASS"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::device_vector", "tail_type": "CUDA_CLASS"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::default_random_engine", "tail_type": "CUDA_CLASS"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::uniform_real_distribution", "tail_type": "CUDA_CLASS"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::uniform_int_distribution", "tail_type": "CUDA_CLASS"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::sort", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::sort_by_key", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::copy", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "thrust::is_sorted", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "testSort", "head_type": "__host__", "description": "A function that tests the sorting of elements using Thrust.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu", "model_response": [{"head": "simpleKernel", "head_type": "__global__", "description": "A kernel that fills a memory buffer with a specified value.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "simpleKernel", "head_type": "__global__", "description": "A kernel that fills a memory buffer with a specified value.", "relation": "calls", "tail": "cudaGetLastError", "tail_type": "CUDA_API"}, {"head": "simpleKernel", "head_type": "__global__", "description": "A kernel that fills a memory buffer with a specified value.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "barrierWait", "head_type": "__host__", "description": "Implements a barrier synchronization mechanism.", "relation": "calls", "tail": "cpu_atomic_add32", "tail_type": "CUDA_API"}, {"head": "barrierWait", "head_type": "__host__", "description": "Implements a barrier synchronization mechanism.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "childProcess", "head_type": "__host__", "description": "Handles operations of the child process in IPC.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "Handles operations of the child process in IPC.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "Handles operations of the child process in IPC.", "relation": "calls", "tail": "cudaGetLastError", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "Handles operations of the child process in IPC.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "Handles operations of the child process in IPC.", "relation": "calls", "tail": "checkIpcErrors", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "Handles operations of the parent process in IPC.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "Handles operations of the parent process in IPC.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "Handles operations of the parent process in IPC.", "relation": "calls", "tail": "cudaMemPoolExportPointer", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "Handles operations of the parent process in IPC.", "relation": "calls", "tail": "cudaMemPoolCreate", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "Handles operations of the parent process in IPC.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu", "model_response": [{"head": "shfl_scan_test", "head_type": "__global__", "description": "This function demonstrates basic use of the shuffle intrinsic, __shfl_up, to perform a scan operation across a block.", "relation": "calls", "tail": "__shfl_up_sync", "tail_type": "CUDA_API"}, {"head": "shfl_scan_test", "head_type": "__global__", "description": "This function demonstrates basic use of the shuffle intrinsic, __shfl_up, to perform a scan operation across a block.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "uniform_add", "head_type": "__global__", "description": "Add partial sums array.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "uniform_add", "head_type": "__global__", "description": "Add partial sums array.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "shuffle_simple_test", "head_type": "__global__", "description": "This function tests simple summation using shuffle intrinsic.", "relation": "calls", "tail": "shfl_scan_test", "tail_type": "CUDA_API"}, {"head": "shuffle_simple_test", "head_type": "__global__", "description": "This function tests simple summation using shuffle intrinsic.", "relation": "calls", "tail": "uniform_add", "tail_type": "CUDA_API"}, {"head": "shuffle_integral_image_test", "head_type": "__global__", "description": "This function tests creation of an integral image using synthetic data.", "relation": "calls", "tail": "shfl_intimage_rows", "tail_type": "CUDA_API"}, {"head": "shuffle_integral_image_test", "head_type": "__global__", "description": "This function tests creation of an integral image using synthetic data.", "relation": "calls", "tail": "shfl_vertical_shfl", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu", "model_response": [{"head": "reduce", "head_type": "__global__", "description": "This function performs a reduction operation on the input data.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "reduceSinglePass", "head_type": "__global__", "description": "This function performs a single-pass reduction operation on the input data.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "benchmarkReduce", "head_type": "__host__", "description": "This function performs multiple reduction operations and measures the time taken.", "relation": "calls", "tail": "reduce", "tail_type": "CUDA_API"}, {"head": "benchmarkReduce", "head_type": "__host__", "description": "This function performs multiple reduction operations and measures the time taken.", "relation": "calls", "tail": "reduceSinglePass", "tail_type": "CUDA_API"}, {"head": "shmoo", "head_type": "__host__", "description": "This function calls benchmarkReduce multiple times for a range of input sizes and prints a report.", "relation": "calls", "tail": "reduce", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "This function runs various tests including the shmoo test for performance evaluation.", "relation": "calls", "tail": "shmoo", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu", "model_response": [{"head": "sequence_gpu", "head_type": "__global__", "description": "The kernel sequence_gpu initializes an array with lane IDs.", "relation": "calls", "tail": "asm", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA runtime errors.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMallocHost", "head_type": "__host__", "description": "Allocates page-locked memory accessible to the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "__host__", "description": "Frees page-locked memory allocated by cudaMallocHost.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error code produced by any of the runtime calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Blocks until all preceding tasks on the GPU are complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "findCudaDevice", "head_type": "__host__", "description": "Finds and initializes the CUDA device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/cudaGraphsPerfScaling/cudaGraphPerfScaling.cu", "model_response": [{"head": "empty", "head_type": "__global__", "description": "This kernel does nothing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "__globaltimer", "head_type": "__device__", "description": "Reads the GPU nanosecond timer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "delay", "head_type": "__global__", "description": "Delays execution in a kernel for a specified number of ticks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "waitWithTimeout", "head_type": "__global__", "description": "Waits for a specified time or until a latch is not zero.", "relation": "calls", "tail": "__globaltimer", "tail_type": "CUDA_API"}, {"head": "waitWithTimeout", "head_type": "__global__", "description": "Waits for a specified time or until a latch is not zero.", "relation": "calls", "tail": "timeoutDetected", "tail_type": "CUDA_CLASS"}, {"head": "waitWithTimeout", "head_type": "__global__", "description": "Waits for a specified time or until a latch is not zero.", "relation": "calls", "tail": "timeElapsed", "tail_type": "CUDA_CLASS"}, {"head": "waitWithTimeout", "head_type": "__global__", "description": "Waits for a specified time or until a latch is not zero.", "relation": "calls", "tail": "latch", "tail_type": "CUDA_CLASS"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates a parallel chain of CUDA streams and events.", "relation": "calls", "tail": "cudaStreamBeginCapture", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates a parallel chain of CUDA streams and events.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates a parallel chain of CUDA streams and events.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "createParallelChain", "head_type": "__host__", "description": "Creates a parallel chain of CUDA streams and events.", "relation": "calls", "tail": "cudaStreamEndCapture", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphInstantiateWithFlags", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphLaunch", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphUpload", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphExecDestroy", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphDestroy", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaGraphInstantiateWithFlags", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "runDemo", "head_type": "__host__", "description": "Runs the demo on a given CUDA graph.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/transpose/transpose.cu", "model_response": [{"head": "copy", "head_type": "__global__", "description": "This kernel copies data from input array to output array.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "copySharedMem", "head_type": "__global__", "description": "This kernel copies data using shared memory for improved performance.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "transposeNaive", "head_type": "__global__", "description": "This kernel performs a naive transpose of a matrix.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "transposeCoalesced", "head_type": "__global__", "description": "This kernel performs a coalesced transpose of a matrix, minimizing bank conflicts.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "transposeNoBankConflicts", "head_type": "__global__", "description": "This kernel performs a transpose of a matrix without bank conflicts.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "transposeDiagonal", "head_type": "__global__", "description": "This kernel performs a transpose by reordering execution along diagonals.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "transposeFineGrained", "head_type": "__global__", "description": "This kernel performs a fine-grained transpose of a matrix.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "transposeCoarseGrained", "head_type": "__global__", "description": "This kernel performs a coarse-grained transpose of a matrix.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/alignedTypes/alignedTypes.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "A simple CUDA kernel that copies data from one device array to another on a per-element basis.", "relation": "calls", "tail": "iDivUp", "tail_type": "CUDA_API"}, {"head": "testKernel", "head_type": "__global__", "description": "A simple CUDA kernel that copies data from one device array to another on a per-element basis.", "relation": "calls", "tail": "iDivDown", "tail_type": "CUDA_API"}, {"head": "testKernel", "head_type": "__global__", "description": "A simple CUDA kernel that copies data from one device array to another on a per-element basis.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs the CUDA kernel for the specified type and handles memory operations.", "relation": "calls", "tail": "testKernel", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs the CUDA kernel for the specified type and handles memory operations.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs the CUDA kernel for the specified type and handles memory operations.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "testCPU", "head_type": "__host__", "description": "Validates the output of the CUDA kernel by comparing packed data between host arrays.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "testCPU", "head_type": "__host__", "description": "Validates the output of the CUDA kernel by comparing packed data between host arrays.", "relation": "calls", "tail": "sdkGetTimerValue", "tail_type": "CUDA_API"}, {"head": "testCPU", "head_type": "__host__", "description": "Validates the output of the CUDA kernel by comparing packed data between host arrays.", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/6_Performance/LargeKernelParameter/LargeKernelParameter.cu", "model_response": [{"head": "kernelDefault", "head_type": "__global__", "description": "Kernel with 4KB kernel parameter limit", "relation": "calls", "tail": "cudaMemcpyToSymbol", "tail_type": "CUDA_API"}, {"head": "kernelDefault", "head_type": "__global__", "description": "Kernel with 4KB kernel parameter limit", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "kernelLargeParam", "head_type": "__global__", "description": "Kernel with 32,764 byte kernel parameter limit", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "kernelLargeParam", "head_type": "__global__", "description": "Kernel with 32,764 byte kernel parameter limit", "relation": "calls", "tail": "cudaMemcpyToSymbol", "tail_type": "CUDA_API"}, {"head": "report_time", "head_type": "__host__", "description": "Reports the execution time of a CUDA kernel.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Utility function to check the result of CUDA operations.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Utility function to check the result of CUDA operations.", "relation": "calls", "tail": "cudaMemcpyToSymbol", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Utility function to check the result of CUDA operations.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Utility function to check the result of CUDA operations.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu", "model_response": [{"head": "init_host_matrices", "head_type": "__host__", "description": "Initializes the host matrices for the computation.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compute_bf16gemm", "head_type": "__global__", "description": "Kernel that computes the result of a matrix multiplication.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm", "head_type": "__global__", "description": "Kernel that computes the result of a matrix multiplication.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Kernel that computes the result of a matrix multiplication with async copy.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_bf16gemm_async_copy", "head_type": "__global__", "description": "Kernel that computes the result of a matrix multiplication with async copy.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_bf16gemm", "head_type": "__global__", "description": "Performs a simple MxNxK bf16 GEMM.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_bf16gemm", "head_type": "__global__", "description": "Performs a simple MxNxK bf16 GEMM.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu", "model_response": [{"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "compute_center", "tail_type": "CUDA_API"}, {"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "set_bounding_box", "tail_type": "CUDA_API"}, {"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "set_range", "tail_type": "CUDA_API"}, {"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "num_points", "tail_type": "CUDA_API"}, {"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "get_point", "tail_type": "CUDA_API"}, {"head": "build_quadtree_kernel", "head_type": "__global__", "description": "Kernel function to build a quadtree on the GPU.", "relation": "calls", "tail": "set_point", "tail_type": "CUDA_API"}, {"head": "check_quadtree", "head_type": "__host__", "description": "Checks if the quadtree is properly defined.", "relation": "calls", "tail": "num_points", "tail_type": "CUDA_API"}, {"head": "check_quadtree", "head_type": "__host__", "description": "Checks if the quadtree is properly defined.", "relation": "calls", "tail": "contains", "tail_type": "CUDA_API"}, {"head": "Random_generator", "head_type": "__host__ __device__", "description": "Random number generator struct.", "relation": "calls", "tail": "thrust::make_tuple", "tail_type": "CUDA_API"}, {"head": "Random_generator", "head_type": "__host__ __device__", "description": "Random number generator struct.", "relation": "calls", "tail": "default_random_engine", "tail_type": "CUDA_API"}, {"head": "Random_generator", "head_type": "__host__ __device__", "description": "Random number generator struct.", "relation": "calls", "tail": "uniform_real_distribution", "tail_type": "CUDA_API"}, {"head": "Random_generator", "head_type": "__host__ __device__", "description": "Random number generator struct.", "relation": "calls", "tail": "generate", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu", "model_response": [{"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::this_grid", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::binary_partition", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::reduce", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "oddEvenCountAndSumCG", "head_type": "__global__", "description": "Creates cooperative groups and performs odd/even counting & summation.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data from host to device asynchronously.", "relation": "calls", "tail": "cudaMemcpyHostToDevice", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data from device to host asynchronously.", "relation": "calls", "tail": "cudaMemcpyDeviceToHost", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Blocks until the specified stream is complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaOccupancyMaxPotentialBlockSize", "head_type": "__host__", "description": "Calculates the maximum potential block size for a given kernel.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a new stream with the specified flags.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu", "model_response": [{"head": "__btflo", "head_type": "__device__", "description": "Inline PTX call to return index of highest non-zero bit in a word", "relation": "single", "tail": "", "tail_type": ""}, {"head": "qcompare", "head_type": "__device__", "description": "Comparison function that compares two unsigned integers.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "bitonicsort_kernel", "head_type": "__device__", "description": "Basic any-N bitonic sort kernel that sorts elements of indata.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "bitonicsort_kernel", "head_type": "__device__", "description": "Basic any-N bitonic sort kernel that sorts elements of indata.", "relation": "calls", "tail": "__shared__", "tail_type": "CUDA_CLASS"}, {"head": "big_bitonicsort_kernel", "head_type": "__device__", "description": "Emergency-CTA sort kernel that sorts an arbitrary sized chunk using a single block.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "bitonicsort", "head_type": "__global__", "description": "Kernel function that sorts arrays using the bitonic sort algorithm.", "relation": "calls", "tail": "bitonicsort_kernel", "tail_type": "CUDA_API"}, {"head": "big_bitonicsort", "head_type": "__global__", "description": "Kernel function that sorts arrays using the big bitonic sort algorithm.", "relation": "calls", "tail": "big_bitonicsort_kernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu", "model_response": [{"head": "ringbufAlloc", "head_type": "__device__", "description": "Allocates from a ringbuffer.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "ringbufFree", "head_type": "__device__", "description": "Releases an element from the ring buffer.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "Simplest possible implementation of per-warp quicksort.", "relation": "calls", "tail": "qsort_warp", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "Simplest possible implementation of per-warp quicksort.", "relation": "calls", "tail": "big_bitonicsort", "tail_type": "CUDA_API"}, {"head": "qsort_warp", "head_type": "__global__", "description": "Simplest possible implementation of per-warp quicksort.", "relation": "calls", "tail": "bitonicsort", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "__host__", "description": "Host-side code to run the Kepler version of quicksort.", "relation": "calls", "tail": "qsort_warp", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "__host__", "description": "Host-side code to run the Kepler version of quicksort.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "run_quicksort_cdp", "head_type": "__host__", "description": "Host-side code to run the Kepler version of quicksort.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "run_qsort", "head_type": "__host__", "description": "Sets up the test for quicksort.", "relation": "calls", "tail": "run_quicksort_cdp", "tail_type": "CUDA_API"}, {"head": "run_qsort", "head_type": "__host__", "description": "Sets up the test for quicksort.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu", "model_response": [{"head": "init_host_matrices", "head_type": "__host__", "description": "Initializes host matrices A, B, and C.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compute_gemm", "head_type": "__global__", "description": "Computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm", "head_type": "__global__", "description": "Computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm", "head_type": "__global__", "description": "Computes the result of a matrix multiplication and addition: D = alpha * A * B + beta * C.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs a MxNxK GEMM (C=alpha*A*B + beta*C) assuming matrices are packed in memory.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs a MxNxK GEMM (C=alpha*A*B + beta*C) assuming matrices are packed in memory.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs a MxNxK GEMM (C=alpha*A*B + beta*C) assuming matrices are packed in memory.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu", "model_response": [{"head": "cdp_kernel", "head_type": "__global__", "description": "The kernel using CUDA dynamic parallelism.", "relation": "calls", "tail": "cdp_kernel", "tail_type": "CUDA_API"}, {"head": "print_info", "head_type": "__device__", "description": "Print a simple message to signal the block which is currently executing.", "relation": "calls", "tail": "printf", "tail_type": "CUDA_API"}, {"head": "cdp_kernel", "head_type": "__global__", "description": "The kernel using CUDA dynamic parallelism.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "print_info", "head_type": "__device__", "description": "Print a simple message to signal the block which is currently executing.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu", "model_response": [{"head": "squareArray", "head_type": "__global__", "description": "Stores the square of each input element in output array.", "relation": "calls", "tail": "cudaGraphAddKernelNode", "tail_type": "CUDA_API"}, {"head": "negateArray", "head_type": "__global__", "description": "Stores the negative of each input element in output array.", "relation": "calls", "tail": "cudaGraphAddKernelNode", "tail_type": "CUDA_API"}, {"head": "createFreeGraph", "head_type": "CUDA_API", "description": "Creates a CUDA graph for freeing memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "CUDA_API", "description": "Demonstrates explicitly creating a CUDA graph including memory nodes.", "relation": "calls", "tail": "squareArray", "tail_type": "CUDA_API"}, {"head": "createNegateSquaresGraphExplicitly", "head_type": "CUDA_API", "description": "Demonstrates explicitly creating a CUDA graph including memory nodes.", "relation": "calls", "tail": "negateArray", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "CUDA_API", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "squareArray", "tail_type": "CUDA_API"}, {"head": "doNegateSquaresInStream", "head_type": "CUDA_API", "description": "Adds work to a CUDA stream which negates the square of values in the input array.", "relation": "calls", "tail": "negateArray", "tail_type": "CUDA_API"}, {"head": "validateGPU", "head_type": "__global__", "description": "Validates the GPU computations by comparing with reference arrays.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu", "model_response": [{"head": "printMemoryFootprint", "head_type": "__host__", "description": "Prints the memory footprint of the specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGetGraphMemAttribute", "head_type": "__host__", "description": "Retrieves a specified graph memory attribute from the device.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "prepareAllocParams", "head_type": "__host__", "description": "Prepares allocation parameters for CUDA memory allocation.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGraphCreate", "head_type": "__host__", "description": "Creates a new graph.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphAddMemAllocNode", "head_type": "__host__", "description": "Adds a memory allocation node to a graph.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphAddMemFreeNode", "head_type": "__host__", "description": "Adds a memory free node to a graph.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphInstantiate", "head_type": "__host__", "description": "Instantiates a graph for execution.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphDestroy", "head_type": "__host__", "description": "Destroys a graph and frees associated resources.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a new stream with specified flags.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphLaunch", "head_type": "__host__", "description": "Launches a graph in a specified stream.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Blocks until the specified stream is complete.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Deallocates memory space previously allocated by cudaMalloc.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGraphMemTrim", "head_type": "__host__", "description": "Trims the graph memory on the specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "clockBlock", "head_type": "__global__", "description": "A kernel that runs for a specified number of clock counts.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGraphAddKernelNode", "head_type": "__host__", "description": "Adds a kernel execution node to a graph.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Retrieves the properties of a specified device.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDriverGetVersion", "head_type": "__host__", "description": "Gets the version of the installed CUDA driver.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Gets a device attribute.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu", "model_response": [{"head": "memcpy_kernel", "head_type": "__global__", "description": "Copies data from source to destination arrays in a GPU kernel.", "relation": "calls", "tail": "memcpy_kernel", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device memory.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in a CUDA stream.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "Waits for an event to complete.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the elapsed time between two events.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaStreamCreateWithPriority", "head_type": "__host__", "description": "Creates a CUDA stream with a specified priority.", "relation": "calls", "tail": "cudaStreamCreateWithPriority", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetStreamPriorityRange", "head_type": "__host__", "description": "Gets the stream priority range for the device.", "relation": "calls", "tail": "cudaDeviceGetStreamPriorityRange", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu", "model_response": [{"head": "init_host_matrices", "head_type": "__host__", "description": "Initializes the host matrices with random values.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compute_tf32gemm", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with shared memory.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with shared memory.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with shared memory.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with async copy.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with async copy.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_tf32gemm_async_copy", "head_type": "__global__", "description": "Computes matrix multiplication and addition using tf32 with async copy.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "Performs an MxNxK tf32 GEMM with no reliance on shared memory.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "Performs an MxNxK tf32 GEMM with no reliance on shared memory.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_tf32gemm", "head_type": "__global__", "description": "Performs an MxNxK tf32 GEMM with no reliance on shared memory.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/graphConditionalNodes/graphConditionalNodes.cu", "model_response": [{"head": "ifGraphKernelA", "head_type": "__global__", "description": "This kernel sets the condition variable to true if *dPtr is odd.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "ifGraphKernelC", "head_type": "__global__", "description": "This kernel prints a message from the GPU when called.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "doWhileEmptyKernel", "head_type": "__global__", "description": "This kernel prints a message from the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "doWhileLoopKernel", "head_type": "__global__", "description": "This kernel decrements a device memory location and sets the condition value to false when it reaches zero.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "capturedWhileKernel", "head_type": "__global__", "description": "This kernel decrements the device memory location and sets the condition when the location is non-zero.", "relation": "calls", "tail": "cudaGraphSetConditional", "tail_type": "CUDA_API"}, {"head": "capturedWhileEmptyKernel", "head_type": "__global__", "description": "This kernel prints a message from the GPU.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu", "model_response": [{"head": "MatrixMulAsyncCopyMultiStageLargeChunk", "head_type": "__global__", "description": "Multi Stage memcpy_async pipeline with large chunk copy.", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyMultiStageLargeChunk", "head_type": "__global__", "description": "Multi Stage memcpy_async pipeline with large chunk copy.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyLargeChunk", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk.", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyLargeChunk", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyLargeChunkAWBarrier", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk using arrive-wait barrier.", "relation": "calls", "tail": "cuda::barrier", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyLargeChunkAWBarrier", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with Large copy chunk using arrive-wait barrier.", "relation": "calls", "tail": "cuda::memcpy_async", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopySingleStage", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with float copy.", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopySingleStage", "head_type": "__global__", "description": "Single Stage memcpy_async pipeline with float copy.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyMultiStage", "head_type": "__global__", "description": "Multi Stage memcpy_async thread_scope_thread pipeline with single-element async-copy.", "relation": "calls", "tail": "cuda::pipeline", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyMultiStage", "head_type": "__global__", "description": "Multi Stage memcpy_async thread_scope_thread pipeline with single-element async-copy.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "MatrixMulAsyncCopyMultiStageSharedState", "head_type": "__global__", "description": "Multi Stage shared state memcpy_async pipeline thread_scope_block.", "relation": "calls", "tail": "cuda::pipeline_shared_state", "tail_type": "CUDA_CLASS"}, {"head": "MatrixMulAsyncCopyMultiStageSharedState", "head_type": "__global__", "description": "Multi Stage shared state memcpy_async pipeline thread_scope_block.", "relation": "calls", "tail": "cuda::make_pipeline", "tail_type": "CUDA_API"}, {"head": "MatrixMulNaive", "head_type": "__global__", "description": "Matrix multiplication (CUDA Kernel) on the device: C = A * B.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "MatrixMulNaiveLargeChunk", "head_type": "__global__", "description": "Matrix multiplication with large chunk.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu", "model_response": [{"head": "init_host_matrices", "head_type": "__host__", "description": "Initializes matrices A, B, and C on the host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compute_dgemm", "head_type": "__global__", "description": "Performs matrix multiplication and addition in the compute_dgemm kernel.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm", "head_type": "__global__", "description": "Performs matrix multiplication and addition in the compute_dgemm kernel.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs asynchronous matrix multiplication and addition in the compute_dgemm_async_copy kernel.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_async_copy", "head_type": "__global__", "description": "Performs asynchronous matrix multiplication and addition in the compute_dgemm_async_copy kernel.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs cooperative group asynchronous matrix multiplication and addition in the compute_dgemm_cg_async_copy kernel.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_dgemm_cg_async_copy", "head_type": "__global__", "description": "Performs cooperative group asynchronous matrix multiplication and addition in the compute_dgemm_cg_async_copy kernel.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs a simple matrix multiplication using the WMMA API.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm", "head_type": "__global__", "description": "Performs a simple matrix multiplication using the WMMA API.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu", "model_response": [{"head": "reduce", "head_type": "__global__", "description": "This function performs reduction on an input vector.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "reduce", "head_type": "__global__", "description": "This function performs reduction on an input vector.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduce", "head_type": "__global__", "description": "This function performs reduction on an input vector.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "reduce", "head_type": "__global__", "description": "This function performs reduction on an input vector.", "relation": "calls", "tail": "tile32.shfl_down", "tail_type": "CUDA_API"}, {"head": "reduceFinal", "head_type": "__global__", "description": "This function performs final reduction on an input vector.", "relation": "calls", "tail": "cg::this_thread_block", "tail_type": "CUDA_CLASS"}, {"head": "reduceFinal", "head_type": "__global__", "description": "This function performs final reduction on an input vector.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "reduceFinal", "head_type": "__global__", "description": "This function performs final reduction on an input vector.", "relation": "calls", "tail": "cg::tiled_partition", "tail_type": "CUDA_API"}, {"head": "cudaGraphsManual", "head_type": "__host__", "description": "This function sets up and executes a manual CUDA graph.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphsManual", "head_type": "__host__", "description": "This function sets up and executes a manual CUDA graph.", "relation": "calls", "tail": "cudaGraphCreate", "tail_type": "CUDA_API"}, {"head": "cudaGraphsManual", "head_type": "__host__", "description": "This function sets up and executes a manual CUDA graph.", "relation": "calls", "tail": "cudaGraphAddMemcpyNode", "tail_type": "CUDA_API"}, {"head": "cudaGraphsManual", "head_type": "__host__", "description": "This function sets up and executes a manual CUDA graph.", "relation": "calls", "tail": "cudaGraphAddKernelNode", "tail_type": "CUDA_API"}, {"head": "cudaGraphsUsingStreamCapture", "head_type": "__host__", "description": "This function demonstrates CUDA graph usage with stream capture.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaGraphsUsingStreamCapture", "head_type": "__host__", "description": "This function demonstrates CUDA graph usage with stream capture.", "relation": "calls", "tail": "cudaGraphBeginCapture", "tail_type": "CUDA_API"}, {"head": "cudaGraphsUsingStreamCapture", "head_type": "__host__", "description": "This function demonstrates CUDA graph usage with stream capture.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaGraphsUsingStreamCapture", "head_type": "__host__", "description": "This function demonstrates CUDA graph usage with stream capture.", "relation": "calls", "tail": "cudaMemsetAsync", "tail_type": "CUDA_API"}, {"head": "cudaGraphsUsingStreamCapture", "head_type": "__host__", "description": "This function demonstrates CUDA graph usage with stream capture.", "relation": "calls", "tail": "cudaLaunchHostFunc", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu", "model_response": [{"head": "atomicAggInc", "head_type": "__device__", "description": "Performs an aggregate increment operation atomically.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "filter_arr", "head_type": "__global__", "description": "Filters the input array and writes results to the destination array.", "relation": "calls", "tail": "atomicAggInc", "tail_type": "CUDA_API"}, {"head": "atomicAggIncMulti", "head_type": "__device__", "description": "Performs an aggregate increment operation into multiple buckets atomically.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "mapToBuckets", "head_type": "__global__", "description": "Maps input array indices into their corresponding buckets.", "relation": "calls", "tail": "atomicAggIncMulti", "tail_type": "CUDA_API"}, {"head": "atomicAggMaxMulti", "head_type": "__device__", "description": "Performs an aggregate max operation in multiple buckets atomically.", "relation": "calls", "tail": "atomicMax", "tail_type": "CUDA_API"}, {"head": "calculateMaxInEachBuckets", "head_type": "__global__", "description": "Calculates the maximum value in each bucket of a source array.", "relation": "calls", "tail": "atomicAggMaxMulti", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemset", "head_type": "__host__", "description": "Sets memory on the device to a specified value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Retrieves attributes of the specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees device memory.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu", "model_response": [{"head": "computeBezierLinePositions", "head_type": "__global__", "description": "Calculates positions of Bezier curve vertices.", "relation": "calls", "tail": "operator+", "tail_type": "CUDA_API"}, {"head": "computeBezierLinePositions", "head_type": "__global__", "description": "Calculates positions of Bezier curve vertices.", "relation": "calls", "tail": "operator*", "tail_type": "CUDA_API"}, {"head": "computeBezierLinesCDP", "head_type": "__global__", "description": "Computes Bezier lines using CUDA Dynamic Parallelism.", "relation": "calls", "tail": "length", "tail_type": "CUDA_API"}, {"head": "computeBezierLinesCDP", "head_type": "__global__", "description": "Computes Bezier lines using CUDA Dynamic Parallelism.", "relation": "calls", "tail": "computeBezierLinePositions", "tail_type": "CUDA_API"}, {"head": "freeVertexMem", "head_type": "__global__", "description": "Frees memory allocated for vertex positions.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCapableSM35Device", "head_type": "none", "description": "Checks if the device is capable of running SM 3.5.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "checkCapableSM35Device", "head_type": "none", "description": "Checks if the device is capable of running SM 3.5.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "checkCapableSM35Device", "head_type": "none", "description": "Checks if the device is capable of running SM 3.5.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "checkCapableSM35Device", "head_type": "none", "description": "Checks if the device is capable of running SM 3.5.", "relation": "calls", "tail": "getCmdLineArgumentInt", "tail_type": "CUDA_API"}, {"head": "checkCapableSM35Device", "head_type": "none", "description": "Checks if the device is capable of running SM 3.5.", "relation": "calls", "tail": "checkCmdLineFlag", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/newdelete/newdelete.cu", "model_response": [{"head": "vectorCreate", "head_type": "__global__", "description": "Allocates a Vector object in device memory.", "relation": "calls", "tail": "Vector<int>", "tail_type": "CUDA_CLASS"}, {"head": "containerFill", "head_type": "__global__", "description": "Fills the Container object with data.", "relation": "calls", "tail": "push", "tail_type": "CUDA_API"}, {"head": "containerConsume", "head_type": "__global__", "description": "Consumes data from the Container object.", "relation": "calls", "tail": "pop", "tail_type": "CUDA_API"}, {"head": "containerDelete", "head_type": "__global__", "description": "Deletes the Container object.", "relation": "calls", "tail": "delete", "tail_type": "CUDA_API"}, {"head": "placementNew", "head_type": "__global__", "description": "Uses placement new to create a Vector object in shared memory.", "relation": "calls", "tail": "Vector<int>", "tail_type": "CUDA_CLASS"}, {"head": "complexVector", "head_type": "__global__", "description": "Handles ComplexType_t in a Vector object.", "relation": "calls", "tail": "Vector<ComplexType_t>", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu", "model_response": [{"head": "cdp_simple_quicksort", "head_type": "__global__", "description": "Very basic quicksort algorithm, recursively launching the next level.", "relation": "calls", "tail": "selection_sort", "tail_type": "CUDA_API"}, {"head": "cdp_simple_quicksort", "head_type": "__global__", "description": "Very basic quicksort algorithm, recursively launching the next level.", "relation": "calls", "tail": "cdp_simple_quicksort", "tail_type": "CUDA_API"}, {"head": "selection_sort", "head_type": "__device__", "description": "Selection sort used when depth gets too big or the number of elements drops below a threshold.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "run_qsort", "head_type": "__host__", "description": "Call the quicksort kernel from the host.", "relation": "calls", "tail": "cdp_simple_quicksort", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu", "model_response": [{"head": "init_host_matrices", "head_type": "__host__", "description": "Initializes the host matrices A, B, and C.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "Kernel that performs matrix multiplication with the WMMA API.", "relation": "calls", "tail": "wmma::fragment", "tail_type": "CUDA_CLASS"}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "Kernel that performs matrix multiplication with the WMMA API.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "Kernel that performs matrix multiplication with the WMMA API.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "compute_gemm_imma", "head_type": "__global__", "description": "Kernel that performs matrix multiplication with the WMMA API.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "Performs a matrix multiplication using WMMA API in a less performant way.", "relation": "calls", "tail": "wmma::fragment", "tail_type": "CUDA_CLASS"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "Performs a matrix multiplication using WMMA API in a less performant way.", "relation": "calls", "tail": "wmma::load_matrix_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "Performs a matrix multiplication using WMMA API in a less performant way.", "relation": "calls", "tail": "wmma::mma_sync", "tail_type": "CUDA_API"}, {"head": "simple_wmma_gemm_imma", "head_type": "__global__", "description": "Performs a matrix multiplication using WMMA API in a less performant way.", "relation": "calls", "tail": "wmma::store_matrix_sync", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "A kernel function that modifies vertex positions in a sine wave pattern.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the simple_vbo_kernel with specified grid and block dimensions.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Maps the OpenGL buffer object for writing from CUDA and calls the launch_kernel function.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs an automated test by launching the CUDA kernel and checking results.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions in sine wave pattern.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the simple_vbo_kernel with the specified parameters.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Runs the CUDA part of the computation.", "relation": "calls", "tail": "cudaGraphicsMapResources", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Runs the CUDA part of the computation.", "relation": "calls", "tail": "cudaGraphicsResourceGetMappedPointer", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs an automated test for CUDA.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "createVBO", "head_type": "__host__", "description": "Creates a Vertex Buffer Object (VBO) and registers it with CUDA.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}, {"head": "deleteVBO", "head_type": "__host__", "description": "Deletes a Vertex Buffer Object (VBO) and unregisters it from CUDA.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks the result of CUDA computations and writes data for regression testing.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks the result of CUDA computations and writes data for regression testing.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/dxtc/dxtc.cu", "model_response": [{"head": "sortColors", "head_type": "__device__", "description": "Sorts colors based on their values.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "loadColorBlock", "head_type": "__device__", "description": "Loads a block of color data from image to shared memory.", "relation": "calls", "tail": "colorSums", "tail_type": "CUDA_API"}, {"head": "loadColorBlock", "head_type": "__device__", "description": "Loads a block of color data from image to shared memory.", "relation": "calls", "tail": "bestFitLine", "tail_type": "CUDA_API"}, {"head": "loadColorBlock", "head_type": "__device__", "description": "Loads a block of color data from image to shared memory.", "relation": "calls", "tail": "dot", "tail_type": "CUDA_API"}, {"head": "loadColorBlock", "head_type": "__device__", "description": "Loads a block of color data from image to shared memory.", "relation": "calls", "tail": "sortColors", "tail_type": "CUDA_API"}, {"head": "evalPermutation4", "head_type": "__device__", "description": "Evaluates permutations for color data.", "relation": "calls", "tail": "roundAndExpand", "tail_type": "CUDA_API"}, {"head": "evalPermutation4", "head_type": "__device__", "description": "Evaluates permutations for color data.", "relation": "calls", "tail": "dot", "tail_type": "CUDA_API"}, {"head": "evalPermutation3", "head_type": "__device__", "description": "Evaluates second set of permutations for color data.", "relation": "calls", "tail": "roundAndExpand", "tail_type": "CUDA_API"}, {"head": "evalPermutation3", "head_type": "__device__", "description": "Evaluates second set of permutations for color data.", "relation": "calls", "tail": "dot", "tail_type": "CUDA_API"}, {"head": "evalAllPermutations", "head_type": "__device__", "description": "Evaluates all permutations and finds the best.", "relation": "calls", "tail": "evalPermutation4", "tail_type": "CUDA_API"}, {"head": "evalAllPermutations", "head_type": "__device__", "description": "Evaluates all permutations and finds the best.", "relation": "calls", "tail": "evalPermutation3", "tail_type": "CUDA_API"}, {"head": "findMinError", "head_type": "__device__", "description": "Finds the index of the minimum error.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "saveBlockDXT1", "head_type": "__device__", "description": "Saves the DXT block to the result.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compress", "head_type": "__global__", "description": "Compresses the image using DXT format.", "relation": "calls", "tail": "loadColorBlock", "tail_type": "CUDA_API"}, {"head": "compress", "head_type": "__global__", "description": "Compresses the image using DXT format.", "relation": "calls", "tail": "evalAllPermutations", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu", "model_response": [{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors after a CUDA API call.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors after a CUDA API call.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors after a CUDA API call.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors after a CUDA API call.", "relation": "calls", "tail": "cudaCreateTextureObject", "tail_type": "CUDA_API"}, {"head": "stereoDisparityKernel", "head_type": "__global__", "description": "The kernel function that computes the stereo disparity.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object for texture memory access.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object for texture memory access.", "relation": "calls", "tail": "cudaCreateChannelDesc", "tail_type": "CUDA_API"}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object for texture memory access.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in the stream.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in the stream.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "cudaEventSynchronize", "head_type": "__host__", "description": "Waits for an event to complete.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the elapsed time between two events.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "sdkSavePGM", "head_type": "__host__", "description": "Saves the disparity image to a PGM file.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu", "model_response": [{"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Counts the number of available GPUs.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaDeviceCanAccessPeer", "head_type": "__host__", "description": "Checks if one device can access the memory of another device.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaDeviceCanAccessPeer", "head_type": "__host__", "description": "Checks if one device can access the memory of another device.", "relation": "calls", "tail": "cudaDeviceEnablePeerAccess", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for CUDA calls.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyPeerAsync", "head_type": "__host__", "description": "Performs an asynchronous memory copy from one device to another.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "__host__", "description": "Creates an event.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaEventRecord", "head_type": "__host__", "description": "Records an event in a stream.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaEventElapsedTime", "head_type": "__host__", "description": "Calculates the elapsed time between two events.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a stream with specified flags.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Waits for all operations in a stream to complete.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaDeviceDisablePeerAccess", "head_type": "__host__", "description": "Disables peer access between two devices.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory from one location to another.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaHostAlloc", "head_type": "__host__", "description": "Allocates page-locked memory on the host.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaMemset", "head_type": "__host__", "description": "Sets a specific value for a region of memory.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaOccupancyMaxPotentialBlockSize", "head_type": "__host__", "description": "Calculates the maximum potential block size for a kernel.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "clock64", "head_type": "__device__", "description": "Returns the current value of the clock counter.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last CUDA error code.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventDestroy", "head_type": "__host__", "description": "Destroys an event.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaFreeHost", "head_type": "__host__", "description": "Frees memory allocated by cudaHostAlloc.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}, {"head": "cudaDeviceEnablePeerAccess", "head_type": "__host__", "description": "Enables peer access between two devices.", "relation": "calls", "tail": "cudaCheckError", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu", "model_response": [{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "initValue", "head_type": "__global__", "description": "Initializes the output data to zero.", "relation": "calls", "tail": "d_odata", "tail_type": "CUDA_API"}, {"head": "dwtHaar1D", "head_type": "__global__", "description": "Performs the Haar wavelet transformation on the input data.", "relation": "calls", "tail": "d_idata", "tail_type": "CUDA_API"}, {"head": "sdkReadFile", "head_type": "__host__", "description": "Reads a file into a buffer.", "relation": "calls", "tail": "signal", "tail_type": "CUDA_API"}, {"head": "sdkWriteFile", "head_type": "__host__", "description": "Writes a buffer to a file.", "relation": "calls", "tail": "r_fname", "tail_type": "CUDA_API"}, {"head": "sdkCompareL2fe", "head_type": "__host__", "description": "Compares two floating-point arrays for equality within a tolerance.", "relation": "calls", "tail": "reference", "tail_type": "CUDA_API"}, {"head": "getLevels", "head_type": "__host__", "description": "Determines the number of decomposition levels for the input signal.", "relation": "calls", "tail": "dlevels_complete", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu", "model_response": [{"head": "d_boxfilter_rgba_x", "head_type": "__global__", "description": "This performs the row pass using texture lookups.", "relation": "calls", "tail": "rgbaFloatToInt", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_x", "head_type": "__global__", "description": "This performs the row pass using texture lookups.", "relation": "calls", "tail": "tex2DLod", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_x", "head_type": "__global__", "description": "This performs the row pass using texture lookups.", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "This performs the column pass using coalesced global memory reads.", "relation": "calls", "tail": "rgbaIntToFloat", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "This performs the column pass using coalesced global memory reads.", "relation": "calls", "tail": "surf2Dread", "tail_type": "CUDA_API"}, {"head": "d_boxfilter_rgba_y", "head_type": "__global__", "description": "This performs the column pass using coalesced global memory reads.", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}, {"head": "varySigma", "head_type": "__host__", "description": "This varies the filter radius for better visualization.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaVkImportImageMem", "head_type": "__host__", "description": "This imports Vulkan image memory for CUDA use.", "relation": "calls", "tail": "cudaMallocMipmappedArray", "tail_type": "CUDA_API"}, {"head": "cudaVkImportImageMem", "head_type": "__host__", "description": "This imports Vulkan image memory for CUDA use.", "relation": "calls", "tail": "cudaGetMipmappedArrayLevel", "tail_type": "CUDA_API"}, {"head": "cudaVkImportImageMem", "head_type": "__host__", "description": "This imports Vulkan image memory for CUDA use.", "relation": "calls", "tail": "cudaCreateSurfaceObject", "tail_type": "CUDA_API"}, {"head": "cudaUpdateVkImage", "head_type": "__host__", "description": "This updates the Vulkan image from CUDA processing.", "relation": "calls", "tail": "cudaVkSemaphoreWait", "tail_type": "CUDA_API"}, {"head": "cudaUpdateVkImage", "head_type": "__host__", "description": "This updates the Vulkan image from CUDA processing.", "relation": "calls", "tail": "d_boxfilter_rgba_x", "tail_type": "CUDA_API"}, {"head": "cudaUpdateVkImage", "head_type": "__host__", "description": "This updates the Vulkan image from CUDA processing.", "relation": "calls", "tail": "d_boxfilter_rgba_y", "tail_type": "CUDA_API"}, {"head": "cudaUpdateVkImage", "head_type": "__host__", "description": "This updates the Vulkan image from CUDA processing.", "relation": "calls", "tail": "varySigma", "tail_type": "CUDA_API"}, {"head": "cudaUpdateVkImage", "head_type": "__host__", "description": "This updates the Vulkan image from CUDA processing.", "relation": "calls", "tail": "cudaVkSemaphoreSignal", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "A kernel that modifies vertex positions in a sine wave pattern.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the simple_vbo_kernel with specified parameters.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Runs CUDA part of the computation by mapping OpenGL buffer for CUDA access.", "relation": "calls", "tail": "cudaGraphicsMapResources", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Runs CUDA part of the computation by mapping OpenGL buffer for CUDA access.", "relation": "calls", "tail": "cudaGraphicsResourceGetMappedPointer", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs automated test for CUDA operations.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Runs automated test for CUDA operations.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks if the result of the CUDA operation is correct.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Checks if the result of the CUDA operation is correct.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}, {"head": "sdkDumpBin2", "head_type": "__host__", "description": "Dumps binary data to a file.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "computeFPS", "head_type": "__host__", "description": "Calculates and updates frames per second.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "error_exit", "head_type": "__host__", "description": "Exits the program in case of an error.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "InitGraphicsState", "head_type": "__host__", "description": "Initializes OpenGL graphics state.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu", "model_response": [{"head": "simple_vbo_kernel", "head_type": "__global__", "description": "Simple kernel to modify vertex positions in sine wave pattern.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "launch_kernel", "head_type": "__host__", "description": "Launches the CUDA kernel to modify vertex positions.", "relation": "calls", "tail": "simple_vbo_kernel", "tail_type": "CUDA_API"}, {"head": "runCuda", "head_type": "__host__", "description": "Run the CUDA part of the computation.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "runAutoTest", "head_type": "__host__", "description": "Run the automatic testing for CUDA execution.", "relation": "calls", "tail": "launch_kernel", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Check if the result is correct or write data to file for external regression testing.", "relation": "calls", "tail": "cudaGraphicsUnregisterResource", "tail_type": "CUDA_API"}, {"head": "checkResultCuda", "head_type": "__host__", "description": "Check if the result is correct or write data to file for external regression testing.", "relation": "calls", "tail": "cudaGraphicsGLRegisterBuffer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/matrixMul/matrixMul.cu", "model_response": [{"head": "MatrixMulCUDA", "head_type": "__global__", "description": "Matrix multiplication (CUDA Kernel) on the device: C = A * B.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaEventDestroy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaProfilerStart", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Check for CUDA function errors.", "relation": "calls", "tail": "cudaProfilerStop", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform a layer of a layered 2D texture using texture lookups", "relation": "calls", "tail": "tex2DLayered", "tail_type": "CUDA_API"}, {"head": "transformKernel", "head_type": "__global__", "description": "Transform a layer of a layered 2D texture using texture lookups", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy3D", "head_type": "__host__", "description": "Copies 3D data from host to device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform a cubemap face of a linear buffer using cubemap texture lookups.", "relation": "calls", "tail": "texCubemap", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy3D", "head_type": "__host__", "description": "Copies 3D data from one memory location to another.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaCreateTextureObject", "head_type": "__host__", "description": "Creates a texture object for texture memory access.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc3DArray", "head_type": "__host__", "description": "Allocates a 3D array in device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Retrieves properties of a device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDestroyTextureObject", "head_type": "__host__", "description": "Destroys a texture object.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "make_cudaExtent", "head_type": "__host__", "description": "Creates a cudaExtent structure for dimensions.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "make_cudaPos", "head_type": "__host__", "description": "Creates a cudaPos structure for positions.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "make_cudaPitchedPtr", "head_type": "__host__", "description": "Creates a cudaPitchedPtr structure.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCmdLineFlag", "head_type": "__host__", "description": "Checks command line flags.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkWriteFile", "head_type": "__host__", "description": "Writes data to a file for regression testing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "compareData", "head_type": "__host__", "description": "Compares output data with a reference.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkCreateTimer", "head_type": "__host__", "description": "Creates a timer for measuring performance.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkStartTimer", "head_type": "__host__", "description": "Starts the timer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkStopTimer", "head_type": "__host__", "description": "Stops the timer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkGetTimerValue", "head_type": "__host__", "description": "Gets the value of the timer.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "sdkDeleteTimer", "head_type": "__host__", "description": "Deletes the timer.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "This kernel prints the value passed to it along with its thread and block indices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Waits for all preceding tasks on the GPU to complete.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDevice", "head_type": "__host__", "description": "Gets the current device ID.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Retrieves properties of a device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "findCudaDevice", "head_type": "__host__", "description": "Finds and returns the best CUDA capable device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "printf", "head_type": "__host__", "description": "Outputs formatted data to stdout.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu", "model_response": [{"head": "reduceKernel", "head_type": "__global__", "description": "A kernel that performs reduction on input data.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "reduceKernel", "head_type": "__global__", "description": "A kernel that performs reduction on input data.", "relation": "calls", "tail": "cudaMemcpyHostToDevice", "tail_type": "CUDA_API"}, {"head": "reduceKernel", "head_type": "__global__", "description": "A kernel that performs reduction on input data.", "relation": "calls", "tail": "cudaMemcpyDeviceToHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaStreamCreate", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Function to check for CUDA errors.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "sdkCreateTimer", "head_type": "__host__", "description": "Creates a timer for measuring performance.", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "sdkStartTimer", "head_type": "__host__", "description": "Starts the timer.", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "sdkGetTimerValue", "head_type": "__host__", "description": "Retrieves the value of the timer.", "relation": "calls", "tail": "sdkDeleteTimer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "A simple test kernel for device functionality.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "findCudaDevice", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "testKernel", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUDA.", "relation": "calls", "tail": "sdkDeleteTimer", "tail_type": "CUDA_API"}, {"head": "computeGold", "head_type": "__host__", "description": "Computes the gold standard of the results.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ArrayComparator", "head_type": "__host__", "description": "A generic wrapper for comparing arrays.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ArrayFileWriter", "head_type": "__host__", "description": "A generic wrapper for writing arrays to a file.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu", "model_response": [{"head": "shiftPitchLinear", "head_type": "__global__", "description": "Shifts matrix elements using pitch linear array.", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "shiftArray", "head_type": "__global__", "description": "Shifts matrix elements using regular array.", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu", "model_response": [{"head": "incKernel", "head_type": "__global__", "description": "A kernel that increments input values by 1.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "incKernel", "head_type": "__global__", "description": "A kernel that increments input values by 1.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Processes data using multiple streams for overlapping execution.", "relation": "calls", "tail": "incKernel", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Processes data using multiple streams for overlapping execution.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "processWithStreams", "head_type": "__host__", "description": "Processes data using multiple streams for overlapping execution.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Entry point of the program that initializes and runs CUDA operations.", "relation": "calls", "tail": "cudaDeviceInit", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Entry point of the program that initializes and runs CUDA operations.", "relation": "calls", "tail": "gpuGetMaxGflopsDeviceId", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Entry point of the program that initializes and runs CUDA operations.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Entry point of the program that initializes and runs CUDA operations.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "main", "head_type": "__host__", "description": "Entry point of the program that initializes and runs CUDA operations.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu", "model_response": [{"head": "clock_block", "head_type": "__global__", "description": "This kernel does no real work but runs at least for a specified number of clocks.", "relation": "calls", "tail": "clock", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "Single warp reduction kernel.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "Single warp reduction kernel.", "relation": "calls", "tail": "d_clocks", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "Single warp reduction kernel.", "relation": "calls", "tail": "s_clocks", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "CUDA_API", "description": "Copies data from device to host asynchronously.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventCreate", "head_type": "CUDA_API", "description": "Creates an event object.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventRecord", "head_type": "CUDA_API", "description": "Records an event in a stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventSynchronize", "head_type": "CUDA_API", "description": "Waits until the event has completed.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamWaitEvent", "head_type": "CUDA_API", "description": "Causes a stream to wait until the specified event occurs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreate", "head_type": "CUDA_API", "description": "Creates a new stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventElapsedTime", "head_type": "CUDA_API", "description": "Calculates the elapsed time between two events.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamDestroy", "head_type": "CUDA_API", "description": "Destroys a stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaEventDestroy", "head_type": "CUDA_API", "description": "Destroys an event.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMallocHost", "head_type": "CUDA_API", "description": "Allocates page-locked host memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "CUDA_API", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "CUDA_API", "description": "Frees page-locked host memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "CUDA_API", "description": "Frees memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "CUDA_API", "description": "Checks for CUDA errors and handles them.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "findCudaDevice", "head_type": "CUDA_API", "description": "Finds the CUDA device suitable for running the application.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "CUDA_API", "description": "Retrieves properties of a specified device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu", "model_response": [{"head": "count_if", "head_type": "__device__", "description": "Counts elements in an array that match a given predicate.", "relation": "calls", "tail": "grid_stride_range", "tail_type": "CUDA_API"}, {"head": "count_if", "head_type": "__device__", "description": "Counts elements in an array that match a given predicate.", "relation": "calls", "tail": "atomicAdd", "tail_type": "CUDA_API"}, {"head": "xyzw_frequency", "head_type": "__global__", "description": "Counts the frequency of 'x', 'y', 'z', or 'w' in a given text.", "relation": "calls", "tail": "count_if", "tail_type": "CUDA_API"}, {"head": "xyzw_frequency_thrust_device", "head_type": "__global__", "description": "Counts the frequency of 'x', 'y', 'z', or 'w' in a given text using Thrust.", "relation": "calls", "tail": "thrust::count_if", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu", "model_response": [{"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicAdd_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicExch_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicMax_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicMin_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicInc_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicDec_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicCAS_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicAnd_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicOr_system", "tail_type": "CUDA_API"}, {"head": "atomicKernel", "head_type": "__global__", "description": "This function performs several atomic operations on an array.", "relation": "calls", "tail": "atomicXor_system", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu", "model_response": [{"head": "cudaMallocManaged", "head_type": "__host__", "description": "Allocates unified memory accessible from the host and device.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Waits for the device to finish all preceding requested tasks.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Deallocates memory previously allocated by cudaMallocManaged.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cublasSetStream", "head_type": "__host__", "description": "Sets the stream for subsequent operations.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaStreamAttachMemAsync", "head_type": "__host__", "description": "Attaches memory to a stream for asynchronous access.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Blocks until the stream has completed all operations.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cublasDgemv", "head_type": "__host__", "description": "Performs the matrix-vector multiplication operation on the device.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu", "model_response": [{"head": "SimpleKernel", "head_type": "__global__", "description": "A dummy kernel that copies and doubles the values from src to dst.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaDeviceCanAccessPeer", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaDeviceEnablePeerAccess", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaEventCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaDeviceDisablePeerAccess", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "A utility function to check CUDA function calls and handle errors.", "relation": "calls", "tail": "cudaEventDestroy", "tail_type": "CUDA_API"}, {"head": "SimpleKernel<<<blocks, threads>>>", "head_type": "__global__", "description": "Launches the SimpleKernel with specified blocks and threads.", "relation": "calls", "tail": "cudaLaunchKernel", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu", "model_response": [{"head": "kernelAddConstant", "head_type": "__global__", "description": "A kernel that increments each array element by a constant value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Retrieves the number of CUDA-capable devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Gets the properties of a specified device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device that is to be used for GPU operations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDevice", "head_type": "__host__", "description": "Gets the currently set device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemset", "head_type": "__host__", "description": "Sets the memory on the device to a specified value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory from the host to the device or vice versa.", "relation": "calls", "tail": "kernelAddConstant", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory from the host to the device or vice versa.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error from a runtime operation.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetErrorString", "head_type": "__host__", "description": "Returns the string representation of an error code.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and reports them.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and reports them.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and reports them.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and reports them.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu", "model_response": [{"head": "transformKernel", "head_type": "__global__", "description": "Transform an image using texture lookups.", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkLoadPGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaCreateChannelDesc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMallocArray", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMemcpyToArray", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaCreateTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "getLastCudaError", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkGetTimerValue", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "compareData", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkLoadPGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkSavePGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkWriteFile", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkDeleteTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaDestroyTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaFreeArray", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu", "model_response": [{"head": "vectorAddGPU", "head_type": "__global__", "description": "Adds two vectors on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and takes appropriate action.", "relation": "calls", "tail": "cudaHostRegister", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and takes appropriate action.", "relation": "calls", "tail": "cudaHostGetDevicePointer", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and takes appropriate action.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and takes appropriate action.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and takes appropriate action.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "getLastCudaError", "head_type": "__host__", "description": "Retrieves the last CUDA error occurred.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaCapabilities", "head_type": "__host__", "description": "Checks the capabilities of the selected CUDA device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu", "model_response": [{"head": "multiplyByTwo", "head_type": "__device__", "description": "This function multiplies a given number by two.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "divideByTwo", "head_type": "__device__", "description": "This function divides a given number by two.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu", "model_response": [{"head": "transformVector", "head_type": "__global__", "description": "Transforms vector applying the device function to each element.", "relation": "calls", "tail": "dMultiplyByTwoPtr", "tail_type": "CUDA_API"}, {"head": "transformVector", "head_type": "__global__", "description": "Transforms vector applying the device function to each element.", "relation": "calls", "tail": "dDivideByTwoPtr", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyFromSymbol", "head_type": "CUDA_API", "description": "Copies data from device symbol to host.", "relation": "calls", "tail": "dMultiplyByTwoPtr", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyFromSymbol", "head_type": "CUDA_API", "description": "Copies data from device symbol to host.", "relation": "calls", "tail": "dDivideByTwoPtr", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "CUDA_API", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaGetLastError", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "CUDA_API", "description": "Copies data between host and device.", "relation": "calls", "tail": "cudaMemcpyHostToDevice", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "CUDA_API", "description": "Copies data between host and device.", "relation": "calls", "tail": "cudaMemcpyDeviceToHost", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu", "model_response": [{"head": "square", "head_type": "__global__", "description": "This kernel squares each array element.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "This wrapper routine computes the occupancy of kernel, and reports it in terms of active warps / maximum warps per SM.", "relation": "calls", "tail": "cudaGetDevice", "tail_type": "CUDA_API"}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "This wrapper routine computes the occupancy of kernel, and reports it in terms of active warps / maximum warps per SM.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "reportPotentialOccupancy", "head_type": "__host__", "description": "This wrapper routine computes the occupancy of kernel, and reports it in terms of active warps / maximum warps per SM.", "relation": "calls", "tail": "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "This function configures the launch based on the automatic argument, records the runtime, and reports occupancy and runtime.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "This function configures the launch based on the automatic argument, records the runtime, and reports occupancy and runtime.", "relation": "calls", "tail": "cudaOccupancyMaxPotentialBlockSize", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "This function configures the launch based on the automatic argument, records the runtime, and reports occupancy and runtime.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "This function configures the launch based on the automatic argument, records the runtime, and reports occupancy and runtime.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "launchConfig", "head_type": "__host__", "description": "This function configures the launch based on the automatic argument, records the runtime, and reports occupancy and runtime.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "The test generates an array and squares it with a CUDA kernel, then verifies the result.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "The test generates an array and squares it with a CUDA kernel, then verifies the result.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "The test generates an array and squares it with a CUDA kernel, then verifies the result.", "relation": "calls", "tail": "launchConfig", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "The test generates an array and squares it with a CUDA kernel, then verifies the result.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "test", "head_type": "__host__", "description": "The test generates an array and squares it with a CUDA kernel, then verifies the result.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu", "model_response": [{"head": "checkErrors1", "head_type": "__host__", "description": "Checks for errors in the results for Vote.Any.", "relation": "calls", "tail": "printf", "tail_type": "CUDA_API"}, {"head": "checkErrors2", "head_type": "__host__", "description": "Checks for errors in the results for Vote.All.", "relation": "calls", "tail": "printf", "tail_type": "CUDA_API"}, {"head": "checkResultsVoteAnyKernel1", "head_type": "__host__", "description": "Verifies results from Vote.Any kernel execution.", "relation": "calls", "tail": "checkErrors1", "tail_type": "CUDA_API"}, {"head": "checkResultsVoteAnyKernel1", "head_type": "__host__", "description": "Verifies results from Vote.Any kernel execution.", "relation": "calls", "tail": "checkErrors2", "tail_type": "CUDA_API"}, {"head": "checkResultsVoteAllKernel2", "head_type": "__host__", "description": "Verifies results from Vote.All kernel execution.", "relation": "calls", "tail": "checkErrors1", "tail_type": "CUDA_API"}, {"head": "checkResultsVoteAllKernel2", "head_type": "__host__", "description": "Verifies results from Vote.All kernel execution.", "relation": "calls", "tail": "checkErrors2", "tail_type": "CUDA_API"}, {"head": "checkResultsVoteAnyKernel3", "head_type": "__host__", "description": "Verifies results from the third Vote.Any/All kernel execution.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu", "model_response": [{"head": "simpleKernel", "head_type": "__global__", "description": "This is a simple kernel that fills an array with a given value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "barrierWait", "head_type": "__host__", "description": "This function implements a barrier synchronization mechanism.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaIpcOpenMemHandle", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaIpcOpenEventHandle", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaStreamWaitEvent", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "childProcess", "head_type": "__host__", "description": "This function represents a child process that performs computations on a GPU.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaIpcGetMemHandle", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaIpcGetEventHandle", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaEventDestroy", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "parentProcess", "head_type": "__host__", "description": "This function represents the parent process that manages child processes and IPC.", "relation": "calls", "tail": "sharedMemoryClose", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu", "model_response": [{"head": "sumReduction", "head_type": "__device__", "description": "calculates the sum of val across the group g.", "relation": "calls", "tail": "g.sync", "tail_type": "CUDA_API"}, {"head": "sumReduction", "head_type": "__device__", "description": "calculates the sum of val across the group g.", "relation": "calls", "tail": "g.thread_rank", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "sumReduction", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "this_thread_block", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "tiled_partition", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "threadBlockGroup.sync", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "tiledPartition16.thread_rank", "tail_type": "CUDA_API"}, {"head": "cgkernel", "head_type": "__global__", "description": "Creates cooperative groups and performs reductions", "relation": "calls", "tail": "tiledPartition16.thread_rank", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu", "model_response": [{"head": "reduceBlockData", "head_type": "__device__", "description": "Reduces block data using a barrier and thread block tile.", "relation": "calls", "tail": "cuda::barrier", "tail_type": "CUDA_CLASS"}, {"head": "reduceBlockData", "head_type": "__device__", "description": "Reduces block data using a barrier and thread block tile.", "relation": "calls", "tail": "sqrt", "tail_type": "CUDA_API"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "Normalizes vectors A and B by calculating the dot product with barriers.", "relation": "calls", "tail": "reduceBlockData", "tail_type": "CUDA_API"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "Normalizes vectors A and B by calculating the dot product with barriers.", "relation": "calls", "tail": "cg::thread_block", "tail_type": "CUDA_CLASS"}, {"head": "normVecByDotProductAWBarrier", "head_type": "__global__", "description": "Normalizes vectors A and B by calculating the dot product with barriers.", "relation": "calls", "tail": "cg::grid_group", "tail_type": "CUDA_CLASS"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaLaunchCooperativeKernel", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runNormVecByDotProductAWBarrier", "head_type": "function", "description": "Runs the normalization of vectors by dot product with barriers.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu", "model_response": [{"head": "testKernel", "head_type": "__global__", "description": "This kernel tests the assert function for a given thread id.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "runTest", "head_type": "__host__", "description": "This function runs the test by setting up the kernel launch parameters and invoking the kernel.", "relation": "calls", "tail": "testKernel", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "This function runs the test by setting up the kernel launch parameters and invoking the kernel.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "findCudaDevice", "head_type": "__host__", "description": "This function selects the best possible CUDA capable device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetErrorString", "head_type": "__host__", "description": "This function retrieves the error string for a given error code.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu", "model_response": [{"head": "vectorAdd", "head_type": "__global__", "description": "Computes the vector addition of A and B into C.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees allocated memory on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetLastError", "head_type": "__host__", "description": "Returns the last error that occurred on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetErrorString", "head_type": "__host__", "description": "Returns a string representing the error code.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/cppOverload/cppOverload.cu", "model_response": [{"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Gets the number of CUDA-capable devices.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "findCudaDevice", "head_type": "__host__", "description": "Finds the CUDA device based on command line options.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaGetDeviceProperties", "head_type": "__host__", "description": "Retrieves properties for a specific device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to the specified device ID.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaMallocHost", "head_type": "__host__", "description": "Allocates pinned host memory.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies data from host to device or device to host.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFuncSetCacheConfig", "head_type": "__host__", "description": "Sets the preferred cache configuration for a function.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFuncGetAttributes", "head_type": "__host__", "description": "Retrieves attributes of a function.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFreeHost", "head_type": "__host__", "description": "Frees pinned host memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Synchronizes the device.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu", "model_response": [{"head": "init_array", "head_type": "__global__", "description": "This kernel initializes an array to a specific value.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "init_array", "head_type": "__global__", "description": "This kernel initializes an array to a specific value.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "init_array", "head_type": "__global__", "description": "This kernel initializes an array to a specific value.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "init_array", "head_type": "__global__", "description": "This kernel initializes an array to a specific value.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "AllocateHostMemory", "head_type": "N/A", "description": "Allocates host memory for the array.", "relation": "calls", "tail": "cudaHostRegister", "tail_type": "CUDA_API"}, {"head": "AllocateHostMemory", "head_type": "N/A", "description": "Allocates host memory for the array.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "FreeHostMemory", "head_type": "N/A", "description": "Frees the allocated host memory.", "relation": "calls", "tail": "cudaFreeHost", "tail_type": "CUDA_API"}, {"head": "FreeHostMemory", "head_type": "N/A", "description": "Frees the allocated host memory.", "relation": "calls", "tail": "cudaHostUnregister", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventCreateWithFlags", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamCreate", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaGetDeviceCount", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "N/A", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaGetDeviceProperties", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu", "model_response": [{"head": "increment_kernel", "head_type": "__global__", "description": "This kernel increments each element of an integer array by a specified value.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaMallocHost", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaMemset", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaDeviceSynchronize", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaProfilerStart", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors and handles them appropriately.", "relation": "calls", "tail": "cudaEventDestroy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu", "model_response": [{"head": "surfaceWriteKernel", "head_type": "__global__", "description": "Write to a cuArray (texture data source) using surface writes", "relation": "calls", "tail": "surf2Dwrite", "tail_type": "CUDA_API"}, {"head": "transformKernel", "head_type": "__global__", "description": "Transform an image using texture lookups", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkLoadPGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaCreateChannelDesc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaMallocArray", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaCreateSurfaceObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaCreateTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkStartTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkSavePGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "compareData", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkWriteFile", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "sdkLoadPGM", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaDestroySurfaceObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaDestroyTextureObject", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA", "relation": "calls", "tail": "cudaFreeArray", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu", "model_response": [{"head": "kernCacheSegmentTest", "head_type": "__global__", "description": "Simple test kernel for device functionality.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "kernCacheSegmentTest", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaStreamSetAttribute", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "cudaCtxResetPersistingL2Cache", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkCreateTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkStopTimer", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Run a simple test for CUDA.", "relation": "calls", "tail": "sdkDeleteTimer", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/clock/clock.cu", "model_response": [{"head": "timedReduction", "head_type": "__global__", "description": "This kernel computes a standard parallel reduction and evaluates the time it takes to do that for each block.", "relation": "calls", "tail": "clock", "tail_type": "CUDA_API"}, {"head": "timedReduction", "head_type": "__global__", "description": "This kernel computes a standard parallel reduction and evaluates the time it takes to do that for each block.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "timedReduction", "head_type": "__global__", "description": "This kernel computes a standard parallel reduction and evaluates the time it takes to do that for each block.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees memory allocated on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors in API calls.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu", "model_response": [{"head": "clock_block", "head_type": "__device__", "description": "This subroutine does no real work but runs for at least the specified number of clock ticks.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "kernel_A", "head_type": "__global__", "description": "Kernel A calls clock_block to perform timing operations.", "relation": "calls", "tail": "clock_block", "tail_type": "CUDA_API"}, {"head": "kernel_B", "head_type": "__global__", "description": "Kernel B calls clock_block to perform timing operations.", "relation": "calls", "tail": "clock_block", "tail_type": "CUDA_API"}, {"head": "sum", "head_type": "__global__", "description": "Single-warp reduction kernel that sums clock values.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu", "model_response": [{"head": "reduceInShared_intrinsics", "head_type": "__device__", "description": "This function reduces the values in shared memory using intrinsics.", "relation": "calls", "tail": "__hadd2", "tail_type": "CUDA_API"}, {"head": "reduceInShared_intrinsics", "head_type": "__device__", "description": "This function reduces the values in shared memory using intrinsics.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "reduceInShared_native", "head_type": "__device__", "description": "This function reduces the values in shared memory using native operations.", "relation": "calls", "tail": "__syncthreads", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_intrinsics", "head_type": "__global__", "description": "This kernel computes the scalar product of two vectors using intrinsics.", "relation": "calls", "tail": "reduceInShared_intrinsics", "tail_type": "CUDA_API"}, {"head": "scalarProductKernel_native", "head_type": "__global__", "description": "This kernel computes the scalar product of two vectors using native operations.", "relation": "calls", "tail": "reduceInShared_native", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu", "model_response": [{"head": "runTest", "head_type": "__host__", "description": "This function parses arguments and runs the appropriate tests.", "relation": "calls", "tail": "testBandwidth", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "This function runs a bandwidth test based on the specified mode.", "relation": "calls", "tail": "testBandwidthQuick", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "This function runs a bandwidth test based on the specified mode.", "relation": "calls", "tail": "testBandwidthRange", "tail_type": "CUDA_API"}, {"head": "testBandwidth", "head_type": "__host__", "description": "This function runs a bandwidth test based on the specified mode.", "relation": "calls", "tail": "testBandwidthShmoo", "tail_type": "CUDA_API"}, {"head": "testBandwidthQuick", "head_type": "__host__", "description": "This function runs a quick mode bandwidth test.", "relation": "calls", "tail": "testBandwidthRange", "tail_type": "CUDA_API"}, {"head": "testBandwidthRange", "head_type": "__host__", "description": "This function runs a range mode bandwidth test.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "testBandwidthRange", "head_type": "__host__", "description": "This function runs a range mode bandwidth test.", "relation": "calls", "tail": "testDeviceToHostTransfer", "tail_type": "CUDA_API"}, {"head": "testBandwidthRange", "head_type": "__host__", "description": "This function runs a range mode bandwidth test.", "relation": "calls", "tail": "testHostToDeviceTransfer", "tail_type": "CUDA_API"}, {"head": "testBandwidthRange", "head_type": "__host__", "description": "This function runs a range mode bandwidth test.", "relation": "calls", "tail": "testDeviceToDeviceTransfer", "tail_type": "CUDA_API"}, {"head": "testBandwidthShmoo", "head_type": "__host__", "description": "This function runs an intense shmoo mode bandwidth test.", "relation": "calls", "tail": "testDeviceToHostTransfer", "tail_type": "CUDA_API"}, {"head": "testBandwidthShmoo", "head_type": "__host__", "description": "This function runs an intense shmoo mode bandwidth test.", "relation": "calls", "tail": "testHostToDeviceTransfer", "tail_type": "CUDA_API"}, {"head": "testBandwidthShmoo", "head_type": "__host__", "description": "This function runs an intense shmoo mode bandwidth test.", "relation": "calls", "tail": "testDeviceToDeviceTransfer", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to host memory copy.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to host memory copy.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "testDeviceToHostTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to host memory copy.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "testHostToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a host to device memory copy.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "testHostToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a host to device memory copy.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "testHostToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a host to device memory copy.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to device memory copy.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to device memory copy.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "testDeviceToDeviceTransfer", "head_type": "__host__", "description": "This function tests the bandwidth of a device to device memory copy.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu", "model_response": [{"head": "cudaGetDeviceCount", "head_type": "__host__", "description": "Gets the number of CUDA-capable devices.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetP2PAttribute", "head_type": "__host__", "description": "Retrieves P2P attribute between two devices.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}, {"head": "cudaDeviceGetAttribute", "head_type": "__host__", "description": "Gets a device attribute.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu", "model_response": [{"head": "cleanUp", "head_type": "__host__", "description": "Cleans up resources allocated in ResourceList.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the memory allocated on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamDestroy", "head_type": "__host__", "description": "Destroys the specified CUDA stream.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data from the source to the destination asynchronously.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemsetAsync", "head_type": "__host__", "description": "Sets the specified memory on the device to a specified value asynchronously.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaSubmitTask", "head_type": "__host__", "description": "Submits a task to the cuDLA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaMemRegister", "head_type": "__host__", "description": "Registers a memory region for access by the cuDLA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaMemUnregister", "head_type": "__host__", "description": "Unregisters a memory region previously registered with cuDLA.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaCreateDevice", "head_type": "__host__", "description": "Creates a cuDLA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaModuleLoadFromMemory", "head_type": "__host__", "description": "Loads a cuDLA module from memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaModuleGetAttributes", "head_type": "__host__", "description": "Gets attributes of a cuDLA module.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaModuleUnload", "head_type": "__host__", "description": "Unloads a cuDLA module.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaDestroyDevice", "head_type": "__host__", "description": "Destroys a cuDLA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaTask", "head_type": "CUDA_CLASS", "description": "Structure representing a cuDLA task.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu", "model_response": [{"head": "initVectors", "head_type": "__global__", "description": "Initializes the vectors for the conjugate gradient solver.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "r1_div_x", "head_type": "__global__", "description": "Calculates r1 divided by x and stores it in b.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "a_minus", "head_type": "__global__", "description": "Negates the value of a and stores it in na.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "r1_div_x", "head_type": "__global__", "description": "Calculates r1 divided by dot and stores it in a.", "relation": "calls", "tail": "cublasSaxpy", "tail_type": "CUDA_API"}, {"head": "r1_div_x", "head_type": "__global__", "description": "Calculates r1 divided by r0 and stores it in b.", "relation": "calls", "tail": "cusparseSpMV", "tail_type": "CUDA_API"}, {"head": "cusparseSpMV", "head_type": "CUDA_API", "description": "Performs the sparse matrix-vector multiplication using cuSPARSE.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cublasSdot", "head_type": "CUDA_API", "description": "Computes the dot product of two vectors.", "relation": "calls", "tail": "r1_div_x", "tail_type": "__global__"}, {"head": "cublasSaxpy", "head_type": "CUDA_API", "description": "Performs the SAXPY operation.", "relation": "calls", "tail": "a_minus", "tail_type": "__global__"}, {"head": "cusparseSpMV", "head_type": "CUDA_API", "description": "Performs the sparse matrix-vector multiplication with stream support.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cusparseCreateCsr", "head_type": "CUDA_API", "description": "Creates a cuSPARSE matrix in CSR format.", "relation": "calls", "tail": "cusparseDnVecDescr_t", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu", "model_response": [{"head": "gpuSpMV", "head_type": "__device__", "description": "Multiplies a sparse matrix with a vector.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuSaxpy", "head_type": "__device__", "description": "Performs the operation y = a*x + y.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuDotProduct", "head_type": "__device__", "description": "Computes the dot product of two vectors.", "relation": "calls", "tail": "cg::thread_block", "tail_type": "CUDA_CLASS"}, {"head": "gpuCopyVector", "head_type": "__device__", "description": "Copies data from one vector to another.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "gpuScaleVectorAndSaxpy", "head_type": "__device__", "description": "Scales a vector and adds it to another vector.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}, {"head": "multiGpuConjugateGradient", "head_type": "__global__", "description": "Kernel for performing the conjugate gradient method on multiple GPUs.", "relation": "calls", "tail": "PeerGroup", "tail_type": "CUDA_CLASS"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu", "model_response": [{"head": "gpuSpMV", "head_type": "__device__", "description": "Performs sparse matrix-vector multiplication on the GPU.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "gpuSaxpy", "head_type": "__device__", "description": "Computes the operation y = a * x + y on the GPU.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "gpuDotProduct", "head_type": "__device__", "description": "Computes the dot product of two vectors on the GPU.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "gpuScaleVectorAndSaxpy", "head_type": "__device__", "description": "Scales a vector and performs the saxpy operation on the GPU.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "gpuCopyVector", "head_type": "__device__", "description": "Copies data from one vector to another on the GPU.", "relation": "calls", "tail": "cg::sync", "tail_type": "CUDA_API"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "Main kernel for the conjugate gradient method implementation on the GPU.", "relation": "calls", "tail": "gpuSpMV", "tail_type": "CUDA_API"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "Main kernel for the conjugate gradient method implementation on the GPU.", "relation": "calls", "tail": "gpuSaxpy", "tail_type": "CUDA_API"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "Main kernel for the conjugate gradient method implementation on the GPU.", "relation": "calls", "tail": "gpuDotProduct", "tail_type": "CUDA_API"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "Main kernel for the conjugate gradient method implementation on the GPU.", "relation": "calls", "tail": "gpuScaleVectorAndSaxpy", "tail_type": "CUDA_API"}, {"head": "gpuConjugateGradient", "head_type": "__global__", "description": "Main kernel for the conjugate gradient method implementation on the GPU.", "relation": "calls", "tail": "gpuCopyVector", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLALayerwiseStatsHybrid/main.cu", "model_response": [{"head": "cudaFree", "head_type": "__host__", "description": "Frees device memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device to be used for subsequent CUDA calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaCreateDevice", "head_type": "__host__", "description": "Creates a cuDLA device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaModuleLoadFromMemory", "head_type": "__host__", "description": "Loads a module into cuDLA from memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a new CUDA stream with specified flags.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaModuleGetAttributes", "head_type": "__host__", "description": "Retrieves attributes from a cuDLA module.", "relation": "calls", "tail": "cudlaModuleTensorDescriptor", "tail_type": "CUDA_CLASS"}, {"head": "cudlaMemRegister", "head_type": "__host__", "description": "Registers memory with cuDLA.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data between host and device asynchronously.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemsetAsync", "head_type": "__host__", "description": "Sets memory on the device asynchronously.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaSubmitTask", "head_type": "__host__", "description": "Submits a cuDLA task for execution.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Waits for the specified stream to finish.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudlaMemUnregister", "head_type": "__host__", "description": "Unregisters memory with cuDLA.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu", "model_response": [{"head": "ComplexPointwiseMulAndScale", "head_type": "__device__", "description": "This is the callback routine for pointwise multiplication and scaling.", "relation": "calls", "tail": "ComplexMul", "tail_type": "CUDA_API"}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__device__", "description": "This is the callback routine for pointwise multiplication and scaling.", "relation": "calls", "tail": "ComplexScale", "tail_type": "CUDA_API"}, {"head": "ComplexAdd", "head_type": "__device__", "description": "Complex addition.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexScale", "head_type": "__device__", "description": "Complex scale.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexMul", "head_type": "__device__", "description": "Complex multiplication.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "PadData", "head_type": "__host__", "description": "Pads the input signal and filter kernel.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cufftCreate", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cufftMakePlan1d", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cufftXtSetCallback", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cufftExecC2C", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cudaMemcpy", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "cudaMemcpyFromSymbol", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "CudaGetDeviceProperties", "tail_type": "CUDA_API"}, {"head": "runTest", "head_type": "__host__", "description": "Runs a simple test for CUFFT callbacks.", "relation": "calls", "tail": "checkCudaErrors", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu", "model_response": [{"head": "cufftCreate", "head_type": "__host__", "description": "Creates an empty plan for FFT.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtSetGPUs", "head_type": "__host__", "description": "Defines which GPUs to use for the FFT plan.", "relation": "calls", "tail": "cufftCreate", "tail_type": "CUDA_API"}, {"head": "cufftMakePlan1d", "head_type": "__host__", "description": "Creates the plan for 1D FFT.", "relation": "calls", "tail": "cufftCreate", "tail_type": "CUDA_API"}, {"head": "cufftXtMalloc", "head_type": "__host__", "description": "Allocates data on multiple GPUs for FFT.", "relation": "calls", "tail": "cufftMakePlan1d", "tail_type": "CUDA_API"}, {"head": "cufftXtMemcpy", "head_type": "__host__", "description": "Copies data between host and device or between devices.", "relation": "calls", "tail": "cufftXtMalloc", "tail_type": "CUDA_API"}, {"head": "cufftXtExecDescriptorC2C", "head_type": "__host__", "description": "Executes the FFT on the data on multiple GPUs.", "relation": "calls", "tail": "cufftXtMemcpy", "tail_type": "CUDA_API"}, {"head": "cufftDestroy", "head_type": "__host__", "description": "Destroys the FFT plan.", "relation": "calls", "tail": "cufftCreate", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the device for subsequent CUDA calls.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaDeviceSynchronize", "head_type": "__host__", "description": "Waits for the device to finish before continuing.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA runtime errors.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Performs pointwise multiplication and scaling of complex numbers.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexAdd", "head_type": "__device__", "description": "Adds two complex numbers.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexScale", "head_type": "__device__", "description": "Scales a complex number by a given scalar.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexMul", "head_type": "__device__", "description": "Multiplies two complex numbers.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu", "model_response": [{"head": "cufftCreate", "head_type": "__host__", "description": "Creates an empty plan for CUFFT.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtSetGPUs", "head_type": "__host__", "description": "Defines which GPUs to use for the cufft plan.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftMakePlan2d", "head_type": "__host__", "description": "Creates a 2D FFT plan.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtMalloc", "head_type": "__host__", "description": "Allocates data on multiple GPUs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtMemcpy", "head_type": "__host__", "description": "Copies data between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftXtExecDescriptorC2C", "head_type": "__host__", "description": "Executes an FFT on input data on multiple GPUs.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cufftDestroy", "head_type": "__host__", "description": "Destroys the CUFFT plan.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the current device for CUDA operations.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the GPU.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaMemcpy", "head_type": "__host__", "description": "Copies memory between host and device.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees GPU memory.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "solvePoissonEquation", "head_type": "__host__", "description": "Solves the Poisson equation using CUDA.", "relation": "calls", "tail": "solvePoisson", "tail_type": "CUDA_API"}, {"head": "solvePoisson", "head_type": "__global__", "description": "Kernel for solving the Poisson equation on GPU.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu", "model_response": [{"head": "cleanUp", "head_type": "__host__", "description": "Cleans up the resources in the ResourceList structure.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the allocated memory for the inputBufferGPU.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the allocated memory for the outputBufferGPU.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cudaStreamDestroy", "head_type": "__host__", "description": "Destroys the CUDA stream.", "relation": "calls", "tail": "cudaStreamDestroy", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the GPU for the input buffer.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaMalloc", "head_type": "__host__", "description": "Allocates memory on the GPU for the output buffer.", "relation": "calls", "tail": "cudaMalloc", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data from the host to the device asynchronously.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaMemsetAsync", "head_type": "__host__", "description": "Sets a region of device memory to a given value asynchronously.", "relation": "calls", "tail": "cudaMemsetAsync", "tail_type": "CUDA_API"}, {"head": "cudaMemcpyAsync", "head_type": "__host__", "description": "Copies data from the device back to the host asynchronously.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, {"head": "cudaStreamSynchronize", "head_type": "__host__", "description": "Blocks until all operations on the specified stream are complete.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, {"head": "cudaSetDevice", "head_type": "__host__", "description": "Sets the current device for subsequent CUDA API calls.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the input buffer on the GPU.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cudaFree", "head_type": "__host__", "description": "Frees the output buffer on the GPU.", "relation": "calls", "tail": "cudaFree", "tail_type": "CUDA_API"}, {"head": "cudaStreamCreateWithFlags", "head_type": "__host__", "description": "Creates a CUDA stream with specified flags.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu", "model_response": [{"head": "computeAngles_kernel", "head_type": "__global__", "description": "Computes view angles for each point along the ray.", "relation": "calls", "tail": "getLocation", "tail_type": "CUDA_API"}, {"head": "computeAngles_kernel", "head_type": "__global__", "description": "Computes view angles for each point along the ray.", "relation": "calls", "tail": "tex2D", "tail_type": "CUDA_API"}, {"head": "computeAngles_kernel", "head_type": "__global__", "description": "Computes view angles for each point along the ray.", "relation": "calls", "tail": "getAngle", "tail_type": "CUDA_API"}, {"head": "computeVisibilities_kernel", "head_type": "__global__", "description": "Computes visibility for each point along the ray.", "relation": "calls", "tail": "scannedAngles", "tail_type": "CUDA_API"}, {"head": "lineOfSight_gold", "head_type": "__host__", "description": "Computes reference data set for visibility results.", "relation": "calls", "tail": "getLocation", "tail_type": "CUDA_API"}, {"head": "lineOfSight_gold", "head_type": "__host__", "description": "Computes reference data set for visibility results.", "relation": "calls", "tail": "getAngle", "tail_type": "CUDA_API"}, {"head": "getLocation", "head_type": "__device__ __host__", "description": "Computes the 2D coordinates of the point located at i steps from the origin of the ray.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "getAngle", "head_type": "__device__ __host__", "description": "Computes the angle of view between a 3D point and the origin of the ray.", "relation": "single", "tail": "", "tail_type": ""}]}
{"cu_path": "/home/fanximing/cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu", "model_response": [{"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Kernel for pointwise multiplication and scaling of complex numbers.", "relation": "calls", "tail": "ComplexScale", "tail_type": "CUDA_API"}, {"head": "ComplexPointwiseMulAndScale", "head_type": "__global__", "description": "Kernel for pointwise multiplication and scaling of complex numbers.", "relation": "calls", "tail": "ComplexMul", "tail_type": "CUDA_API"}, {"head": "ComplexAdd", "head_type": "__device__ __host__", "description": "Performs addition of two complex numbers.", "relation": "calls", "tail": "ComplexMul", "tail_type": "CUDA_API"}, {"head": "ComplexMul", "head_type": "__device__ __host__", "description": "Performs multiplication of two complex numbers.", "relation": "single", "tail": "", "tail_type": ""}, {"head": "ComplexScale", "head_type": "__device__ __host__", "description": "Scales a complex number by a given factor.", "relation": "single", "tail": "", "tail_type": ""}]}
